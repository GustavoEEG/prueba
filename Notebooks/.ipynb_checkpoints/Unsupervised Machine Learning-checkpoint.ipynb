{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28d31c2a",
   "metadata": {},
   "source": [
    "# Unsupervised Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c99c299",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4607b9",
   "metadata": {},
   "source": [
    "One example of a clustering algorithm that can be used for unsupervised learning is the k-means algorithm. In k-means clustering, the objective is to partition a given dataset into K non-overlapping clusters, where K is a predetermined value. Each data point is assigned to only one of the K clusters based on its similarity to the centroid, or center point, of the cluster. The centroids are iteratively updated until the cluster assignments stabilize, resulting in a final set of clusters. Unlike hierarchical clustering, k-means clustering does not create a hierarchical structure of nested clusters, and each data point is assigned to only one cluster. This makes k-means more suitable for datasets with a large number of data points and where non-overlapping clusters are desired. However, the performance of k-means clustering can be sensitive to the initial placement of the centroids, and it may not work well for datasets with irregular shapes or non-convex clusters. In summary, the k-means algorithm is a clustering algorithm used for unsupervised learning, which partitions a given dataset into K non-overlapping clusters. Each data point is assigned to only one cluster based on its similarity to the centroid of the cluster, and the centroids are updated iteratively until convergence. K-means is suitable for datasets with a large number of data points and non-overlapping clusters but may not work well for irregular or non-convex datasets.\n",
    "\n",
    "Hierarchical clustering is a technique that can be performed in two different ways, namely, top-down and bottom-up clustering. Agglomerative algorithms are examples of bottom-up clustering algorithms. These algorithms start by considering each data point as an individual cluster and then combine smaller clusters progressively into larger ones. This results in a hierarchical structure of nested clusters where each cluster consists of subclusters with different levels of granularity. In contrast, divisive algorithms employ a top-down approach where the entire dataset is considered as one cluster initially. These algorithms then recursively partition the dataset into smaller and more homogeneous clusters until each data point is assigned to a separate cluster. Divisive clustering results in a binary tree structure where each node represents a partition of the data and each leaf node represents a single data point. Both agglomerative and divisive clustering have their advantages and disadvantages, and the choice of algorithm depends on the specific characteristics of the data and the objectives of the analysis. Agglomerative clustering is more efficient for large datasets with a high number of data points, whereas divisive clustering is better suited for datasets with a small number of data points or when the number of clusters is known a priori. In summary, hierarchical clustering can be performed using two different approaches, top-down and bottom-up clustering. Agglomerative algorithms are examples of bottom-up clustering, whereas divisive algorithms use a top-down approach. The choice of clustering algorithm depends on the specific requirements of the data analysis task. In contrast to k-means clustering, hierarchical clustering does not require a predetermined number of clusters as the number of clusters is not known beforehand and is determined based on the similarity or dissimilarity between data points.\n",
    "There are several unsupervised machine learning algorithms available for clustering and dimensionality reduction, including K-Means, Mini Batch K-Means, Ward, and Mean Shift. These algorithms are typically implemented in a standardized way, involving data rescaling, instantiation of the estimator, model fitting, cluster assignment (if required), and algorithm assessment. K-Means clustering is a popular algorithm for unsupervised learning that has been extensively studied and used in various applications. Mini Batch K-Means is a variant of K-Means that is faster and more scalable, making it suitable for large datasets. Ward is a hierarchical clustering algorithm that can be used with or without connectivity constraints. Mean Shift is another clustering algorithm that iteratively moves a kernel to the local mode of the distribution, resulting in clusters that are of varying sizes and shapes. Affinity propagation is another unsupervised learning algorithm that creates clusters by sending messages between pairs of samples until convergence. The algorithm can be computed based on either the Spearman distance or the Euclidean distance, with the similarity measure computed as the opposite of the distance or equality. The preference value for all points can be computed as the median, minimum, or mean value of the similarity values. Affinity propagation is implemented by rescaling the data, computing the similarity and preference values, performing affinity propagation clustering, and assessing the algorithm's performance. Another example is DBSCAN is a density-based spatial clustering algorithm designed for applications with noise. It is an unsupervised clustering method that identifies core samples of high density and expands clusters from them. The algorithm partitions data into clusters by grouping together neighboring data points that satisfy a density criterion, while data points that do not belong to any cluster are considered noise.\n",
    "\n",
    "Unlike other clustering algorithms, DBSCAN can identify clusters of arbitrary shapes that do not need to be convex-shaped. DBSCAN is a deterministic algorithm that produces the same clusters when given the same data in the same order. However, changes to the order of the data may result in different cluster formations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83f794",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3de6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
