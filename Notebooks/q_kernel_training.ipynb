{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c067329b",
   "metadata": {},
   "source": [
    "# q_kernel_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00aaaa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Soma_Surface   N_stems    N_bifs  N_branch    N_tips     Width  \\\n",
      "0          0.838617  0.597598  0.720220  0.718218  0.715215  0.606779   \n",
      "1          0.579659  0.597598  0.536036  0.537037  0.537037  0.495207   \n",
      "2          0.595703  0.456456  0.629129  0.619620  0.609109  0.904932   \n",
      "3          0.388786  0.456456  0.049049  0.078078  0.100100  0.031450   \n",
      "4          0.900423  0.597598  0.865866  0.865866  0.867367  0.951721   \n",
      "...             ...       ...       ...       ...       ...       ...   \n",
      "22251      0.731001  0.894394  0.424424  0.461962  0.496997  0.582912   \n",
      "22252      0.000000  0.000000  0.250751  0.216216  0.176176  0.377306   \n",
      "22253      0.356055  0.894394  0.375876  0.415916  0.452953  0.144144   \n",
      "22254      0.226288  0.158158  0.981730  0.981315  0.980781  0.270687   \n",
      "22255      0.548778  0.597598  0.424424  0.427427  0.431431  0.910963   \n",
      "\n",
      "         Height     Depth      Type  Diameter  ...  Bif_ampl_remote  \\\n",
      "0      0.908276  0.898557  0.901879  0.900733  ...         0.673265   \n",
      "1      0.528093  0.821972  0.467546  0.420879  ...         0.510379   \n",
      "2      0.522061  0.808802  0.650794  0.721180  ...         0.565559   \n",
      "3      0.069778  0.434651  0.145479  0.335097  ...         0.044186   \n",
      "4      0.980125  0.577579  0.657783  0.848137  ...         0.797600   \n",
      "...         ...       ...       ...       ...  ...              ...   \n",
      "22251  0.839732  0.873285  0.288142  0.418590  ...         0.381731   \n",
      "22252  0.349986  0.000000  0.082416  0.017692  ...         0.311111   \n",
      "22253  0.130555  0.121226  0.252002  0.417597  ...         0.451447   \n",
      "22254  0.119055  0.652791  0.950856  0.941540  ...         0.977669   \n",
      "22255  0.812510  0.435085  0.767783  0.376330  ...         0.321237   \n",
      "\n",
      "       Bif_tilt_local  Bif_tilt_remote  Bif_torque_local  Bif_torque_remote  \\\n",
      "0            0.753787         0.742703          0.648596           0.659309   \n",
      "1            0.510946         0.578610          0.520619           0.515007   \n",
      "2            0.649809         0.656998          0.467054           0.523440   \n",
      "3            0.056628         0.038713          0.060470           0.055159   \n",
      "4            0.895883         0.890884          0.866950           0.862963   \n",
      "...               ...              ...               ...                ...   \n",
      "22251        0.351947         0.422641          0.330757           0.366129   \n",
      "22252        0.278363         0.249197          0.095596           0.091091   \n",
      "22253        0.384734         0.364361          0.320221           0.310842   \n",
      "22254        0.989981         0.983736          0.979954           0.980921   \n",
      "22255        0.381329         0.478451          0.350420           0.363967   \n",
      "\n",
      "       Last_parent_diam  Diam_threshold  HillmanThreshold     Helix  \\\n",
      "0              0.766729        0.819816          0.815977  0.014261   \n",
      "1              0.382883        0.461986          0.314958  0.897898   \n",
      "2              0.663664        0.739152          0.695665  0.065814   \n",
      "3              0.373838        0.286031          0.480909  0.366867   \n",
      "4              0.966604        0.962576          0.935497  0.185185   \n",
      "...                 ...             ...               ...       ...   \n",
      "22251          0.493994        0.643987          0.763434  0.909576   \n",
      "22252          0.192192        0.034147          0.033313  0.500000   \n",
      "22253          0.780781        0.666863          0.614143  0.626627   \n",
      "22254          0.971752        0.986089          0.981293  0.822322   \n",
      "22255          0.142142        0.307287          0.352238  0.078745   \n",
      "\n",
      "       Fractal_Dim  \n",
      "0         0.774690  \n",
      "1         0.637044  \n",
      "2         0.686240  \n",
      "3         0.092303  \n",
      "4         0.860855  \n",
      "...            ...  \n",
      "22251     0.516658  \n",
      "22252     0.119110  \n",
      "22253     0.250645  \n",
      "22254     0.982710  \n",
      "22255     0.526619  \n",
      "\n",
      "[22256 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# Loading your IBM Quantum account(s)\n",
    "from qiskit import IBMQ\n",
    "\n",
    "# Import utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Importing standard Qiskit libraries and Qiskit Machine Learning imports\n",
    "from qiskit import Aer, QuantumCircuit, BasicAer\n",
    "from qiskit.circuit.library import ZZFeatureMap, PauliFeatureMap, RealAmplitudes\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit_machine_learning.algorithms import QSVC, PegasosQSVC\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.kernels.algorithms import QuantumKernelTrainer\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "from qiskit.algorithms.optimizers import COBYLA, L_BFGS_B\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.providers.aer import AerSimulator\n",
    "from qiskit.visualization import circuit_drawer\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "from qiskit.circuit import Parameter\n",
    "from typing import Union\n",
    "from qiskit_machine_learning.exceptions import QiskitMachineLearningError\n",
    "\n",
    "# seed for randomization, to keep outputs consistent\n",
    "seed = 123456\n",
    "algorithm_globals.random_seed = seed\n",
    "\n",
    "# Define parameters\n",
    "cv = 5 # Cross-validation \n",
    "feature_dimension = 5 # Features dimension\n",
    "k_features = 5 # Feature selection\n",
    "reps = 2 # Repetition\n",
    "ibm_account = 'YOUR API'\n",
    "quantum_backend = 'ibmq_kolkata'\n",
    "multiclass = None\n",
    "output_folder = None\n",
    "\n",
    "# Import dataset\n",
    "data = 'neurons.csv'\n",
    "neuron = pd.read_csv(data, delimiter=';')\n",
    "\n",
    "df = neuron.head(371).copy()                    # Ganglion\n",
    "df = pd.concat([df, neuron.iloc[373:1410]])     # Granule\n",
    "df = pd.concat([df, neuron.iloc[1411:2272]])   # Medium Spiny\n",
    "df = pd.concat([df, neuron.iloc[2273:2797]])   # Parachromaffin\n",
    "df = pd.concat([df, neuron.iloc[2840:3294]])   # Purkinje\n",
    "df = pd.concat([df, neuron.iloc[3295:17032]])   # Pyramidal\n",
    "\n",
    "df = pd.concat([df, neuron.iloc[17033:17505]]) # Basket\n",
    "df = pd.concat([df, neuron.iloc[17506:17572]]) # Bitufted\n",
    "df = pd.concat([df, neuron.iloc[17573:17598]]) # Chandelier\n",
    "df = pd.concat([df, neuron.iloc[17599:17648]]) # Double bouquet\n",
    "df = pd.concat([df, neuron.iloc[17649:17785]]) # Martinotti\n",
    "df = pd.concat([df, neuron.iloc[17786:19829]]) # Nitrergic\n",
    "\n",
    "df = pd.concat([df, neuron.iloc[19830:21436]]) # Astrocytes\n",
    "df = pd.concat([df, neuron.iloc[21437:27882]]) # Microglia\n",
    "\n",
    "# Drop row having at least 1 missing value\n",
    "df = df.dropna()\n",
    "\n",
    "# Creating an instance of Labelencoder\n",
    "enc = LabelEncoder()\n",
    "# Assigning numerical value and storing it\n",
    "df[[\"Target\"]] = df[[\"Target\"]].apply(enc.fit_transform)\n",
    "\n",
    "# Divide the data, y the variable to predict (Target) and X the features\n",
    "X = df[df.columns[1:]]\n",
    "y = df['Target']\n",
    "\n",
    "# Splitting the data : training and test (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Scaling the data\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "Normalize = QuantileTransformer(n_quantiles=1000, output_distribution=\"uniform\")\n",
    "# Transform data\n",
    "X_train = Normalize.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns = X.columns)\n",
    "X_test = Normalize.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns = X.columns)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29c8ab19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "XGBoost Classification Features Importance: started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Features Importances:\n",
      "\n",
      "\n",
      "                 Features  Importances\n",
      "0            Soma_Surface     0.045172\n",
      "1                 N_stems     0.017756\n",
      "2                  N_bifs     0.000033\n",
      "3                N_branch     0.000120\n",
      "4                  N_tips     0.003273\n",
      "5                   Width     0.058583\n",
      "6                  Height     0.358164\n",
      "7                   Depth     0.085577\n",
      "8                    Type     0.101132\n",
      "9                Diameter     0.003813\n",
      "10           Diameter_pow     0.008323\n",
      "11                 Length     0.006621\n",
      "12                Surface     0.005167\n",
      "13            SectionArea     0.002876\n",
      "14                 Volume     0.013751\n",
      "15            EucDistance     0.012023\n",
      "16           PathDistance     0.004511\n",
      "17           Branch_Order     0.000803\n",
      "18        Terminal_degree     0.000779\n",
      "19        TerminalSegment     0.006211\n",
      "20                Taper_1     0.008650\n",
      "21                Taper_2     0.019127\n",
      "22      Branch_pathlength     0.068680\n",
      "23            Contraction     0.001417\n",
      "24          Fragmentation     0.000819\n",
      "25         Daughter_Ratio     0.007284\n",
      "26  Parent_Daughter_Ratio     0.000489\n",
      "27    Partition_asymmetry     0.000728\n",
      "28             Rall_Power     0.051153\n",
      "29                     Pk     0.011441\n",
      "30             Pk_classic     0.000912\n",
      "31                   Pk_2     0.007385\n",
      "32         Bif_ampl_local     0.024488\n",
      "33        Bif_ampl_remote     0.041482\n",
      "34         Bif_tilt_local     0.001493\n",
      "35        Bif_tilt_remote     0.000858\n",
      "36       Bif_torque_local     0.000269\n",
      "37      Bif_torque_remote     0.000272\n",
      "38       Last_parent_diam     0.008995\n",
      "39         Diam_threshold     0.003102\n",
      "40       HillmanThreshold     0.001470\n",
      "41                  Helix     0.000821\n",
      "42            Fractal_Dim     0.003977\n",
      "\n",
      "\n",
      "XGBoost Classification Features Importance: DataFrame\n",
      "\n",
      "\n",
      "         Height      Type     Depth  Branch_pathlength     Width\n",
      "0      0.908276  0.901879  0.898557           0.857664  0.606779\n",
      "1      0.528093  0.467546  0.821972           0.687821  0.495207\n",
      "2      0.522061  0.650794  0.808802           0.739124  0.904932\n",
      "3      0.069778  0.145479  0.434651           0.031525  0.031450\n",
      "4      0.980125  0.657783  0.577579           0.944660  0.951721\n",
      "...         ...       ...       ...                ...       ...\n",
      "22251  0.839732  0.288142  0.873285           0.534289  0.582912\n",
      "22252  0.349986  0.082416  0.000000           0.204021  0.377306\n",
      "22253  0.130555  0.252002  0.121226           0.237322  0.144144\n",
      "22254  0.119055  0.950856  0.652791           0.489980  0.270687\n",
      "22255  0.812510  0.767783  0.435085           0.781391  0.910963\n",
      "\n",
      "[22256 rows x 5 columns]\n",
      "         Height      Type     Depth  Branch_pathlength     Width\n",
      "0      0.908276  0.901879  0.898557           0.857664  0.606779\n",
      "1      0.528093  0.467546  0.821972           0.687821  0.495207\n",
      "2      0.522061  0.650794  0.808802           0.739124  0.904932\n",
      "3      0.069778  0.145479  0.434651           0.031525  0.031450\n",
      "4      0.980125  0.657783  0.577579           0.944660  0.951721\n",
      "...         ...       ...       ...                ...       ...\n",
      "22251  0.839732  0.288142  0.873285           0.534289  0.582912\n",
      "22252  0.349986  0.082416  0.000000           0.204021  0.377306\n",
      "22253  0.130555  0.252002  0.121226           0.237322  0.144144\n",
      "22254  0.119055  0.950856  0.652791           0.489980  0.270687\n",
      "22255  0.812510  0.767783  0.435085           0.781391  0.910963\n",
      "\n",
      "[22256 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def embedded_xgboost_classification(X, y, k_features, output_folder = None):\n",
    "    '''\n",
    "    Here we use XGboost classifier to select features. We select the k best features (k_features)\n",
    "    \n",
    "    Inputs:\n",
    "        - X (features) DataFrame\n",
    "        - y (target) DataFrame\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"XGBoost Classification Features Importance: started\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # define the model\n",
    "    model = GradientBoostingClassifier()\n",
    "    # fit the model\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # get importance\n",
    "    importance = model.feature_importances_\n",
    "    \n",
    "    # Get features name\n",
    "    feature_names = [f\"{i}\" for i in X.columns]\n",
    "\n",
    "    # create a data frame to visualize features importance\n",
    "    features_importance = pd.DataFrame({\"Features\": feature_names, \"Importances\":importance})\n",
    "    features_importance.set_index('Importances')\n",
    "\n",
    "    # Print features importance\n",
    "    print(\"\\n\")\n",
    "    print(\"Features Importances:\")\n",
    "    print(\"\\n\")\n",
    "    print(features_importance)\n",
    "    if output_folder is not None:\n",
    "        features_importance.to_csv(output_folder+'XGBoost_Classification_Features_Importance.csv', index=False)\n",
    "\n",
    "    if output_folder is not None:\n",
    "        # plot feature importance\n",
    "        features_importance.plot(kind='bar',x='Features',y='Importances')\n",
    "        pyplot.title('XGBoost Classification Features Importance')\n",
    "        pyplot.tight_layout()\n",
    "        pyplot.savefig(output_folder+'XGBoost_Classification_Features_Importance.png')\n",
    "    \n",
    "    # Select the k most important features\n",
    "    features_columns = []\n",
    "    # Order the features importance dataframe\n",
    "    df = pd.DataFrame(data = features_importance.sort_values(by='Importances', key=abs,ascending=False))\n",
    "    # Put the k most important features in features_columns\n",
    "    for x in range(k_features):\n",
    "        features_columns = features_columns + [df.iloc[x][0]]\n",
    "\n",
    "    # Create a new DataFrame with selected features\n",
    "    df_data = pd.DataFrame(data = X, columns = features_columns)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"XGBoost Classification Features Importance: DataFrame\")\n",
    "    print(\"\\n\")\n",
    "    print(df_data)\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "X_train = embedded_xgboost_classification(X_train, y_train, k_features)\n",
    "X_test = pd.DataFrame(data = X_test, columns = X_train.columns)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ba9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: θ, ['θ[0]', 'θ[1]', 'θ[2]', 'θ[3]', 'θ[4]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ibmqfactory.load_account:WARNING:2022-09-14 15:35:45,322: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibmq_qasm_simulator\n",
      "ibmq_montreal\n",
      "ibmq_toronto\n",
      "ibmq_kolkata\n",
      "ibmq_mumbai\n",
      "ibmq_lima\n",
      "ibmq_belem\n",
      "ibmq_quito\n",
      "ibmq_guadalupe\n",
      "ibmq_jakarta\n",
      "ibmq_manila\n",
      "ibm_hanoi\n",
      "ibm_lagos\n",
      "ibm_nairobi\n",
      "ibm_cairo\n",
      "ibm_auckland\n",
      "ibm_perth\n",
      "ibm_washington\n",
      "ibm_oslo\n",
      "ibm_geneva\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FAILURE: Job id: 6321da080507c1bedef43ebe is cancelled. Re-submit the circuits.\n"
     ]
    }
   ],
   "source": [
    "def q_kernel_training(X, X_train, X_test, y, y_train, y_test, cv, feature_dimension = None, reps= None, ibm_account = None, quantum_backend = None, multiclass = None, output_folder = None):\n",
    " \n",
    "    # We convert pandas DataFrame into numpy array\n",
    "    X_train = X_train.to_numpy()\n",
    "    X_test = X_test.to_numpy()\n",
    "\n",
    "    # seed for randomization, to keep outputs consistent\n",
    "    seed = 123456\n",
    "    algorithm_globals.random_seed = seed\n",
    "\n",
    "    # Define a callback class for our optimizer\n",
    "    class QKTCallback:\n",
    "        \"\"\"Callback wrapper class.\"\"\"\n",
    "\n",
    "        def __init__(self) -> None:\n",
    "            self._data = [[] for i in range(5)]\n",
    "\n",
    "        def callback(self, x0, x1=None, x2=None, x3=None, x4=None):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                x0: number of function evaluations\n",
    "                x1: the parameters\n",
    "                x2: the function value\n",
    "                x3: the stepsize\n",
    "                x4: whether the step was accepted\n",
    "            \"\"\"\n",
    "            self._data[0].append(x0)\n",
    "            self._data[1].append(x1)\n",
    "            self._data[2].append(x2)\n",
    "            self._data[3].append(x3)\n",
    "            self._data[4].append(x4)\n",
    "\n",
    "        def get_callback_data(self):\n",
    "            return self._data\n",
    "\n",
    "        def clear_callback_data(self):\n",
    "            self._data = [[] for i in range(5)]\n",
    "\n",
    "    # normalize the data between 0 and 2pi\n",
    "    #X_train -= X_train.min(0)\n",
    "    #X_train /= X_train.max(0)\n",
    "    #X_train *= 2*np.pi\n",
    "\n",
    "    # normalize the data between 0 and 2pi\n",
    "    #X_test -= X_test.min(0)\n",
    "    #X_test /= X_test.max(0)\n",
    "    #X_test *= 2*np.pi\n",
    "\n",
    "    # Create a rotational layer to train. We will rotate each qubit the same amount.\n",
    "    user_params = ParameterVector(\"θ\", feature_dimension)\n",
    "    fm0 = QuantumCircuit(feature_dimension)\n",
    "    fm0.ry(user_params[0], 0)\n",
    "    fm0.ry(user_params[1], 1)\n",
    "    fm0.ry(user_params[2], 2)\n",
    "    fm0.ry(user_params[3], 3)\n",
    "    fm0.ry(user_params[4], 4)\n",
    "    \n",
    "    # Use ZZFeatureMap to represent input data\n",
    "    fm1 = ZZFeatureMap(feature_dimension=feature_dimension, reps=2, entanglement=\"linear\")\n",
    "\n",
    "    # Create the feature map, composed of our two circuits\n",
    "    fm = fm0.compose(fm1)\n",
    "\n",
    "    fm.decompose().draw(output=\"mpl\")\n",
    "    print(f\"Trainable parameters: {user_params}\")\n",
    "            \n",
    "    # Use of a real quantum computer\n",
    "    # The use of these requires us to sign with an IBMQ account.\n",
    "    # Assuming the credentials are already loaded onto your computer, you sign in with\n",
    "    IBMQ.save_account(ibm_account, overwrite=True)\n",
    "    IBMQ.load_account()\n",
    "    provider = IBMQ.get_provider(hub='ibm-q-internal', group='deployed', project='default')\n",
    "    # What additional backends we have available.\n",
    "    for backend in provider.backends():\n",
    "        print(backend)\n",
    "                    \n",
    "    backend = provider.get_backend(quantum_backend)\n",
    "    #backend.configuration().default_rep_delay == 0.00001  # Equality test on float is bad\n",
    "    real_qcomp_backend = QuantumInstance(backend, shots=1024)\n",
    "    quant_kernel = QuantumKernel(fm, user_parameters=user_params, quantum_instance=real_qcomp_backend)\n",
    "\n",
    "    # Set up the optimizer\n",
    "    cb_qkt = QKTCallback()\n",
    "    spsa_opt = SPSA(maxiter=10, callback=cb_qkt.callback, learning_rate=0.05, perturbation=0.05)\n",
    "\n",
    "    # Instantiate a quantum kernel trainer.\n",
    "    qkt = QuantumKernelTrainer(\n",
    "        quantum_kernel=quant_kernel, loss=\"svc_loss\", optimizer=spsa_opt, initial_point=[np.pi / 2]*feature_dimension\n",
    "    )\n",
    "\n",
    "    # Train the kernel using QKT directly\n",
    "    qka_results = qkt.fit(X_train, y_train)\n",
    "    optimized_kernel = qka_results.quantum_kernel\n",
    "    print(qka_results)\n",
    "    \n",
    "    model = QSVC(quantum_kernel=optimized_kernel)\n",
    "    \n",
    "    # Fit the QSVC\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if output_folder is not None:\n",
    "        if multiclass is None:\n",
    "            model.save(output_folder+\"q_kernel_training.model\")\n",
    "        \n",
    "    # Evalaute the test accuracy\n",
    "    accuracy_test = metrics.balanced_accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    print(f\"accuracy test: {accuracy_test}\")\n",
    "\n",
    "    # Print predicted values and real values of the X_test dataset\n",
    "    print(\"\\n\")\n",
    "    print(\"Print predicted data coming from X_test as new input data\")\n",
    "    print(y_pred)\n",
    "    print(\"\\n\")\n",
    "    print(\"Print real values\\n\")\n",
    "    print(y_test)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # K-Fold Cross Validation\n",
    "    from sklearn.model_selection import KFold\n",
    "    k_fold = KFold(n_splits=cv)\n",
    "    score = np.zeros(cv)\n",
    "    i = 0\n",
    "    print(score)\n",
    "    for indices_train, indices_test in k_fold.split(X_train):\n",
    "        #print(indices_train, indices_test)\n",
    "        X_train_ = X_train[indices_train]\n",
    "        X_test_ = X_train[indices_test]\n",
    "        y_train_ = y_train[indices_train]\n",
    "        y_test_ = y_train[indices_test]\n",
    " \n",
    "        # fit classifier to data\n",
    "        model.fit(X_train_, y_train_)\n",
    "\n",
    "        # score classifier\n",
    "        score[i] = model.score(X_test_, y_test_)\n",
    "        i = i + 1\n",
    "\n",
    "    import math\n",
    "    print(\"cross validation scores: \", score)\n",
    "    cross_mean = sum(score) / len(score)\n",
    "    cross_var = sum(pow(x - cross_mean,2) for x in score) / len(score)  # variance\n",
    "    cross_std  = math.sqrt(cross_var)  # standard deviation\n",
    "    print(\"cross validation mean: \", cross_mean)\n",
    "    \n",
    "    results = [metrics.accuracy_score(y_test, y_pred),metrics.precision_score(y_test, y_pred, average='micro'),metrics.recall_score(y_test, y_pred, average='micro'),metrics.f1_score(y_test, y_pred, average='micro'), cross_mean, cross_std]\n",
    "    \n",
    "    metrics_dataframe = pd.DataFrame(results, index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Cross-validation mean\", \"Cross-validation std\"], columns=['q_kernel_training'])\n",
    "    print('Classification Report: \\n')\n",
    "    print(classification_report(y_test,y_pred))\n",
    "            \n",
    "    return metrics_dataframe\n",
    "\n",
    "feature_dimension = X_train.shape[1] # Number of features\n",
    "multiclass = None\n",
    "output_folder = None\n",
    "df_results = q_kernel_training(X, X_train, X_test, y, y_train, y_test, cv, feature_dimension, reps, ibm_account, quantum_backend, multiclass, output_folder)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e147a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
