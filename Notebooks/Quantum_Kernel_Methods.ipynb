{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4897c339",
   "metadata": {},
   "source": [
    "# Quantum Kernel Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8108004",
   "metadata": {},
   "source": [
    "To implement our use case, few things need to be considered. As usual, we will import our data, make some preprocessing such as check for missing values, split the data into training and testing datasets, rescale the data using normalization. An important step is feature extraction such as principal component analysis. We need to reduce our data from 43 features to 2 features. We could also use feature selection for dimension reduction. The encoding function is specified in a data_map function (for example data_map_12). The quantum kernels can then be used in a support vector classifier. Here, we will use scikit-learn (from sklearn.svm import SVC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8f57c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "configrc.store_credentials:WARNING:2022-06-05 10:51:25,615: Credentials already present. Set overwrite=True to overwrite.\n"
     ]
    }
   ],
   "source": [
    "# Loading your IBM Quantum account: https://quantum-computing.ibm.com\n",
    "# It requires us to sign with an IBMQ account.\n",
    "from qiskit import IBMQ\n",
    "IBMQ.save_account('Y O U R   A P I')\n",
    "\n",
    "# Import utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Importing standard Qiskit libraries and Qiskit Machine Learning imports\n",
    "from qiskit import BasicAer\n",
    "from qiskit.circuit.library import ZZFeatureMap, PauliFeatureMap\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "from qiskit.algorithms.optimizers import COBYLA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d54a2",
   "metadata": {},
   "source": [
    "Backend objects can also be set up using the IBMQ package.\n",
    "Assuming the credentials are already loaded onto your computer, you sign in with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2500a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IBMQ.load_account()\n",
    "provider = IBMQ.get_provider(hub='ibm-q')\n",
    "backend = provider.get_backend('ibmq_qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296341a",
   "metadata": {},
   "source": [
    "We can also see what additional backends are available. We will see simulators such as ibmq_qasm_simulator and real hardware such as ibmq_belem or ibmq_lima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c8f62b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibmq_qasm_simulator\n",
      "ibmq_armonk\n",
      "ibmq_santiago\n",
      "ibmq_bogota\n",
      "ibmq_lima\n",
      "ibmq_belem\n",
      "ibmq_quito\n",
      "simulator_statevector\n",
      "simulator_mps\n",
      "simulator_extended_stabilizer\n",
      "simulator_stabilizer\n",
      "ibmq_manila\n"
     ]
    }
   ],
   "source": [
    "for backend in provider.backends():\n",
    "    print(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04bc53ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed for randomization, to keep outputs consistent\n",
    "seed = 123456\n",
    "algorithm_globals.random_seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdac5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Functions\n",
    "def data_map_8(x: np.ndarray) -> float:\n",
    "    coeff = x[0] if len(x) == 1 else reduce(lambda m, n: np.pi*(m * n), x)\n",
    "    return coeff\n",
    "\n",
    "def data_map_9(x: np.ndarray) -> float:\n",
    "    coeff = x[0] if len(x) == 1 else reduce(lambda m, n: (np.pi/2)*(m * n), 1 - x)\n",
    "    return coeff\n",
    "\n",
    "def data_map_10(x: np.ndarray) -> float:\n",
    "    coeff = x[0] if len(x) == 1 else reduce(lambda m, n: np.pi*np.exp(((n - m)*(n - m))/8), x)\n",
    "    return coeff\n",
    "\n",
    "def data_map_11(x: np.ndarray) -> float:\n",
    "    coeff = x[0] if len(x) == 1 else reduce(lambda m, n: (np.pi/3)*(m * n), 1/(np.cos(x)))\n",
    "    return coeff\n",
    "\n",
    "def data_map_12(x: np.ndarray) -> float:\n",
    "    coeff = x[0] if len(x) == 1 else reduce(lambda m, n: np.pi*(m * n), np.cos(x))\n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d354c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n",
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n",
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n",
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n",
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n",
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Quantum Feature Mapping with feature_dimension = 2 and reps = 2\n",
    "\n",
    "qfm_default = PauliFeatureMap(feature_dimension=2,\n",
    "                                    paulis = ['ZI','IZ','ZZ'],\n",
    "                                 reps=2, entanglement='full')\n",
    "print(qfm_default)\n",
    "qfm_8 = PauliFeatureMap(feature_dimension=2,\n",
    "                                    paulis = ['ZI','IZ','ZZ'],\n",
    "                                 reps=2, entanglement='full', data_map_func=data_map_8)\n",
    "print(qfm_8)\n",
    "qfm_9 = PauliFeatureMap(feature_dimension=2,\n",
    "                                    paulis = ['ZI','IZ','ZZ'],\n",
    "                                 reps=2, entanglement='full', data_map_func=data_map_9)\n",
    "print(qfm_9)\n",
    "qfm_10 = PauliFeatureMap(feature_dimension=2,\n",
    "                                    paulis = ['ZI','IZ','ZZ'],\n",
    "                                 reps=2, entanglement='full', data_map_func=data_map_10)\n",
    "print(qfm_10)\n",
    "qfm_11 = PauliFeatureMap(feature_dimension=2,\n",
    "                                    paulis = ['ZI','IZ','ZZ'],\n",
    "                                 reps=2, entanglement='full', data_map_func=data_map_11)\n",
    "print(qfm_11)\n",
    "qfm_12 = PauliFeatureMap(feature_dimension=2,\n",
    "                                    paulis = ['ZI','IZ','ZZ'],\n",
    "                                 reps=2, entanglement='full', data_map_func=data_map_12)\n",
    "print(qfm_12)\n",
    "                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27ff463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of a simulator (qasm_simulator)\n",
    "qcomp_backend = QuantumInstance(BasicAer.get_backend('qasm_simulator'), shots=1024,\n",
    "                                seed_simulator=seed, seed_transpiler=seed)\n",
    "Q_Kernel_default = QuantumKernel(feature_map=qfm_default, quantum_instance=qcomp_backend)\n",
    "Q_Kernel_8 = QuantumKernel(feature_map=qfm_8, quantum_instance=qcomp_backend)\n",
    "Q_Kernel_9 = QuantumKernel(feature_map=qfm_9, quantum_instance=qcomp_backend)\n",
    "Q_Kernel_10 = QuantumKernel(feature_map=qfm_10, quantum_instance=qcomp_backend)\n",
    "Q_Kernel_11 = QuantumKernel(feature_map=qfm_11, quantum_instance=qcomp_backend)\n",
    "Q_Kernel_12 = QuantumKernel(feature_map=qfm_12, quantum_instance=qcomp_backend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf85701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativly we can use a real quantum computer (such as 'ibmq_bogota')\n",
    "\n",
    "#real_qcomp_backend = QuantumInstance(provider.get_backend('ibmq_bogota'), shots=32)\n",
    "#Q_Kernel_default = QuantumKernel(feature_map=qfm_default, quantum_instance=real_qcomp_backend)\n",
    "#Q_Kernel_8 = QuantumKernel(feature_map=qfm_8, quantum_instance=real_qcomp_backend)\n",
    "#Q_Kernel_9 = QuantumKernel(feature_map=qfm_9, quantum_instance=real_qcomp_backend)\n",
    "#Q_Kernel_10 = QuantumKernel(feature_map=qfm_10, quantum_instance=real_qcomp_backend)\n",
    "#Q_Kernel_11 = QuantumKernel(feature_map=qfm_11, quantum_instance=real_qcomp_backend)\n",
    "#Q_Kernel_12 = QuantumKernel(feature_map=qfm_12, quantum_instance=real_qcomp_backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5186048",
   "metadata": {},
   "source": [
    "We process our data as we did for classical computing (load data, missing data, split of the data, normalization, PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07693847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PCA_1      PCA_2\n",
      "0    1.435834   4.081395\n",
      "1    5.773557  10.022009\n",
      "2   21.318734  -4.598521\n",
      "3   -3.151619  -1.563259\n",
      "4    0.668559   0.301271\n",
      "5   -1.165522   0.369769\n",
      "6   -0.958028  -1.190758\n",
      "7   -3.716388  -1.479628\n",
      "8   -3.968132  -1.303697\n",
      "9    5.667760  -3.158447\n",
      "10  -0.787751  -0.148257\n",
      "11  -3.506257  -1.179403\n",
      "12  -1.617898   0.087098\n",
      "13  -2.480529  -0.935191\n",
      "14  -4.335223  -1.390716\n",
      "15  -1.048610  -0.730497\n",
      "16   3.124327   3.135691\n",
      "17   3.198947  -1.246605\n",
      "18  -1.282505   2.405743\n",
      "19  -4.256384  -1.492572\n",
      "20  -1.835022   0.466993\n",
      "21  -2.673096  -1.118469\n",
      "22  -3.645921  -1.479659\n",
      "23  -3.763482  -1.566059\n",
      "24  -3.636642  -1.489347\n",
      "25  -1.667317  -1.234876\n",
      "26  -0.849866   5.925350\n",
      "27   1.505479  -2.277992\n",
      "28  -3.051316  -0.371275\n",
      "29   6.733528   1.484747\n",
      "30  -1.095088   3.026743\n",
      "31   5.065872  -1.351583\n",
      "      PCA_1     PCA_2\n",
      "0 -3.569388 -0.568268\n",
      "1  1.036985  6.469456\n",
      "2 -3.763126 -0.032492\n",
      "3  8.208539 -5.295320\n",
      "4  1.561053 -1.076364\n",
      "5 -4.648621 -3.235642\n",
      "6  5.187216  3.940087\n",
      "7 -4.012659 -0.201456\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "data = '../data/datasets/neurons_test.csv'\n",
    "df = pd.read_csv(data, delimiter=';')\n",
    "\n",
    "# Drop row having at least 1 missing value\n",
    "df = df.dropna()\n",
    "\n",
    "# Creating an instance of Labelencoder\n",
    "enc = LabelEncoder()\n",
    "# Assigning numerical value and storing it\n",
    "df[[\"Target\"]] = df[[\"Target\"]].apply(enc.fit_transform)\n",
    "\n",
    "# Divide the data, y the variable to predict (Target) and X the features\n",
    "X = df[df.columns[1:]]\n",
    "y = df['Target']\n",
    "\n",
    "# Splitting the data : training and test (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Scaling the data\n",
    "Normalize = preprocessing.StandardScaler()\n",
    "# Transform data\n",
    "X_train = Normalize.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns = X.columns)\n",
    "X_test = Normalize.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns = X.columns)\n",
    "\n",
    "# Dimension Reduction with PCA (with two principal compoenents)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "# transform data\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.fit_transform(X_test)\n",
    "# Define a new DataFrame with two column (the principal components)\n",
    "component_columns = []\n",
    "for x in (n+1 for n in range(2)):\n",
    "    component_columns = component_columns + ['PCA_%i'%x]\n",
    "X_train = pd.DataFrame(data = X_train, columns = component_columns)\n",
    "X_test = pd.DataFrame(data = X_test, columns = component_columns)\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee579d",
   "metadata": {},
   "source": [
    "Then, we iterate other the different classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60b6565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Q_Kernel_default\", \"Q_Kernel_8\", \"Q_Kernel_9\",\n",
    "         \"Q_Kernel_10\", \"Q_Kernel_11\", \"Q_Kernel_12\"]\n",
    "\n",
    "classifiers = [\n",
    "    SVC(kernel=Q_Kernel_default.evaluate),\n",
    "    SVC(kernel=Q_Kernel_8.evaluate),\n",
    "    SVC(kernel=Q_Kernel_9.evaluate),\n",
    "    SVC(kernel=Q_Kernel_10.evaluate),\n",
    "    SVC(kernel=Q_Kernel_11.evaluate),\n",
    "    SVC(kernel=Q_Kernel_12.evaluate),\n",
    "              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7121ee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callable kernel classification test score for Q_Kernel_default: 0.125\n",
      "Callable kernel classification test score for Q_Kernel_8: 0.125\n",
      "Callable kernel classification test score for Q_Kernel_9: 0.125\n",
      "Callable kernel classification test score for Q_Kernel_10: 0.125\n",
      "Callable kernel classification test score for Q_Kernel_11: 0.25\n",
      "Callable kernel classification test score for Q_Kernel_12: 0.25\n"
     ]
    }
   ],
   "source": [
    "# iterate over classifiers and give classification test score\n",
    "for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print(f'Callable kernel classification test score for {name}: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61486b02",
   "metadata": {},
   "source": [
    "As we also did previously in classical computing, we can provide metrics about our model (Accuracy, Precision, Recall, F1 score, cross validation or use the classification report)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e26c587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Q_Kernel_default\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Print predicted data coming from X_test as new input data\n",
      "[1 1 1 1 1 1 1 1]\n",
      "\n",
      "\n",
      "Print real values\n",
      "\n",
      "9     0\n",
      "30    3\n",
      "19    1\n",
      "35    3\n",
      "0     0\n",
      "21    2\n",
      "3     0\n",
      "29    2\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "\n",
      "Accuracy: 0.125\n",
      "Precision: 0.125\n",
      "Recall: 0.125\n",
      "f1 Score: 0.125\n",
      "Cross Validation Mean: 0.11904761904761904\n",
      "Cross Validation Std: 0.10858813572372743\n",
      "\n",
      "\n",
      "Q_Kernel_8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Print predicted data coming from X_test as new input data\n",
      "[1 2 2 1 2 1 1 2]\n",
      "\n",
      "\n",
      "Print real values\n",
      "\n",
      "9     0\n",
      "30    3\n",
      "19    1\n",
      "35    3\n",
      "0     0\n",
      "21    2\n",
      "3     0\n",
      "29    2\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "\n",
      "Accuracy: 0.125\n",
      "Precision: 0.125\n",
      "Recall: 0.125\n",
      "f1 Score: 0.125\n",
      "Cross Validation Mean: 0.21904761904761902\n",
      "Cross Validation Std: 0.07589227357385346\n",
      "\n",
      "\n",
      "Q_Kernel_9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Print predicted data coming from X_test as new input data\n",
      "[1 1 1 1 1 1 1 1]\n",
      "\n",
      "\n",
      "Print real values\n",
      "\n",
      "9     0\n",
      "30    3\n",
      "19    1\n",
      "35    3\n",
      "0     0\n",
      "21    2\n",
      "3     0\n",
      "29    2\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "\n",
      "Accuracy: 0.125\n",
      "Precision: 0.125\n",
      "Recall: 0.125\n",
      "f1 Score: 0.125\n",
      "Cross Validation Mean: 0.2523809523809524\n",
      "Cross Validation Std: 0.08192690730516787\n",
      "\n",
      "\n",
      "Q_Kernel_10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Print predicted data coming from X_test as new input data\n",
      "[1 1 1 1 1 1 1 1]\n",
      "\n",
      "\n",
      "Print real values\n",
      "\n",
      "9     0\n",
      "30    3\n",
      "19    1\n",
      "35    3\n",
      "0     0\n",
      "21    2\n",
      "3     0\n",
      "29    2\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "\n",
      "Accuracy: 0.125\n",
      "Precision: 0.125\n",
      "Recall: 0.125\n",
      "f1 Score: 0.125\n",
      "Cross Validation Mean: 0.1571428571428571\n",
      "Cross Validation Std: 0.09110060223670947\n",
      "\n",
      "\n",
      "Q_Kernel_11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Print predicted data coming from X_test as new input data\n",
      "[1 2 1 2 1 2 1 1]\n",
      "\n",
      "\n",
      "Print real values\n",
      "\n",
      "9     0\n",
      "30    3\n",
      "19    1\n",
      "35    3\n",
      "0     0\n",
      "21    2\n",
      "3     0\n",
      "29    2\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "\n",
      "Accuracy: 0.25\n",
      "Precision: 0.25\n",
      "Recall: 0.25\n",
      "f1 Score: 0.25\n",
      "Cross Validation Mean: 0.28095238095238095\n",
      "Cross Validation Std: 0.1846735183777649\n",
      "\n",
      "\n",
      "Q_Kernel_12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Print predicted data coming from X_test as new input data\n",
      "[1 3 1 1 3 3 1 1]\n",
      "\n",
      "\n",
      "Print real values\n",
      "\n",
      "9     0\n",
      "30    3\n",
      "19    1\n",
      "35    3\n",
      "0     0\n",
      "21    2\n",
      "3     0\n",
      "29    2\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "\n",
      "Accuracy: 0.25\n",
      "Precision: 0.25\n",
      "Recall: 0.25\n",
      "f1 Score: 0.25\n",
      "Cross Validation Mean: 0.22380952380952376\n",
      "Cross Validation Std: 0.08984743935292004\n",
      "Classification Report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.20      1.00      0.33         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.25         8\n",
      "   macro avg       0.13      0.38      0.18         8\n",
      "weighted avg       0.11      0.25      0.14         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Provide metrics over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "        print(\"\\n\")\n",
    "        print(name)\n",
    "        print(\"\\n\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "    \n",
    "        print(\"\\n\")\n",
    "        print(\"Print predicted data coming from X_test as new input data\")\n",
    "        print(y_pred)\n",
    "        print(\"\\n\")\n",
    "        print(\"Print real values\\n\")\n",
    "        print(y_test)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "        print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "        print(\"Precision:\", metrics.precision_score(y_test, y_pred, average='micro'))\n",
    "        print(\"Recall:\", metrics.recall_score(y_test, y_pred, average='micro'))\n",
    "        print(\"f1 Score:\", metrics.f1_score(y_test, y_pred, average='micro'))\n",
    "        print(\"Cross Validation Mean:\", cross_val_score(clf, X_train, y_train, cv=5).mean())\n",
    "        print(\"Cross Validation Std:\", cross_val_score(clf, X_train, y_train, cv=5).std())\n",
    "\n",
    "print('Classification Report: \\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a59e7a1",
   "metadata": {},
   "source": [
    "## q_kernel_zz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0214d559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b534f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Target  Soma_Surface  N_stems  N_bifs  N_branch  N_tips  \\\n",
      "0            ganglion      1149.320      4.0   101.0     206.0   106.0   \n",
      "1            ganglion      1511.830      3.0    70.0     143.0    74.0   \n",
      "2            ganglion      1831.530      3.0    13.0      29.0    17.0   \n",
      "3            ganglion      1291.270      6.0   109.0     224.0   116.0   \n",
      "4            ganglion      3064.340      4.0    60.0     124.0    65.0   \n",
      "...               ...           ...      ...     ...       ...     ...   \n",
      "22686  double_bouquet       605.067      5.0   132.0     269.0   138.0   \n",
      "22687  double_bouquet       920.949      6.0   121.0     248.0   128.0   \n",
      "22688  double_bouquet       770.529      3.0   104.0     211.0   108.0   \n",
      "22689  double_bouquet       478.078      4.0   158.0     320.0   163.0   \n",
      "22690  double_bouquet       629.470      4.0    65.0     134.0    70.0   \n",
      "\n",
      "        Width   Height   Depth     Type  ...  Bif_ampl_remote  Bif_tilt_local  \\\n",
      "0      249.09   493.80   33.63   1806.0  ...         9132.460         9543.61   \n",
      "1      453.80   390.94   35.00   1504.0  ...         6034.870         6750.98   \n",
      "2      282.23   324.06   29.24    699.0  ...          835.754         1215.33   \n",
      "3      228.86   616.17   42.19   2131.0  ...         9696.640        10160.10   \n",
      "4      264.09   364.24   44.37   1568.0  ...         5084.620         5927.53   \n",
      "...       ...      ...     ...      ...  ...              ...             ...   \n",
      "22686  222.40  1212.65  120.80   6247.0  ...        11348.400        13220.00   \n",
      "22687  328.02   980.65  227.04  32561.0  ...         9996.370        12886.10   \n",
      "22688  247.39  1322.26   96.81   5746.0  ...         7972.950        10343.50   \n",
      "22689  343.21   813.14  115.01   9878.0  ...        11555.700        15740.30   \n",
      "22690  305.82  1164.29  183.69  15343.0  ...         5267.240         6223.78   \n",
      "\n",
      "       Bif_tilt_remote  Bif_torque_local  Bif_torque_remote  Last_parent_diam  \\\n",
      "0              9714.80           7413.60            7348.63             11.24   \n",
      "1              6781.43           6896.19            7620.16              7.75   \n",
      "2              1478.25           1192.02            1001.38              4.06   \n",
      "3             10281.70           9992.69           10400.00              9.38   \n",
      "4              5852.84           5128.55            5371.86              7.73   \n",
      "...                ...               ...                ...               ...   \n",
      "22686         12887.70          12790.80           12031.90             11.41   \n",
      "22687         12170.90          10669.40           10279.20             28.52   \n",
      "22688         10984.10           9389.51           10205.70             10.84   \n",
      "22689         17768.70          14536.90           13063.80             17.55   \n",
      "22690          6298.83           5738.15            6259.83              6.12   \n",
      "\n",
      "       Diam_threshold  HillmanThreshold  Helix  Fractal_Dim  \n",
      "0            114.0480          123.3370  -0.33      56.4171  \n",
      "1            101.5980          103.2830  -0.01      46.9175  \n",
      "2             59.7340           72.2750  -0.64      20.7496  \n",
      "3            125.3340          145.4360  -5.34      49.3177  \n",
      "4            123.6620          140.4000  -1.27      51.0624  \n",
      "...               ...               ...    ...          ...  \n",
      "22686         73.7220           78.2270  -1.86     205.7210  \n",
      "22687         63.8622           95.7028   1.93     239.6990  \n",
      "22688         71.3840           79.0890  -2.71     142.2360  \n",
      "22689         73.8240           81.1340  -3.20     271.7430  \n",
      "22690         44.6384           53.5180 -11.67     124.9970  \n",
      "\n",
      "[22691 rows x 44 columns]\n",
      "\n",
      "\n",
      "Decision Tree Regressor Features Importance: started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Features Importances:\n",
      "\n",
      "\n",
      "                 Features  Importances\n",
      "0            Soma_Surface     0.132398\n",
      "1                 N_stems     0.019728\n",
      "2                  N_bifs     0.000000\n",
      "3                N_branch     0.000000\n",
      "4                  N_tips     0.000000\n",
      "5                   Width     0.000000\n",
      "6                  Height     0.174589\n",
      "7                   Depth     0.070581\n",
      "8                    Type     0.115796\n",
      "9                Diameter     0.000000\n",
      "10           Diameter_pow     0.000000\n",
      "11                 Length     0.000000\n",
      "12                Surface     0.000000\n",
      "13            SectionArea     0.022928\n",
      "14                 Volume     0.000000\n",
      "15            EucDistance     0.000000\n",
      "16           PathDistance     0.095161\n",
      "17           Branch_Order     0.000000\n",
      "18        Terminal_degree     0.000000\n",
      "19        TerminalSegment     0.009220\n",
      "20                Taper_1     0.076445\n",
      "21                Taper_2     0.000000\n",
      "22      Branch_pathlength     0.044744\n",
      "23            Contraction     0.000000\n",
      "24          Fragmentation     0.000000\n",
      "25         Daughter_Ratio     0.024061\n",
      "26  Parent_Daughter_Ratio     0.000000\n",
      "27    Partition_asymmetry     0.000000\n",
      "28             Rall_Power     0.014306\n",
      "29                     Pk     0.008298\n",
      "30             Pk_classic     0.000000\n",
      "31                   Pk_2     0.000000\n",
      "32         Bif_ampl_local     0.066446\n",
      "33        Bif_ampl_remote     0.027766\n",
      "34         Bif_tilt_local     0.000000\n",
      "35        Bif_tilt_remote     0.000000\n",
      "36       Bif_torque_local     0.000000\n",
      "37      Bif_torque_remote     0.000000\n",
      "38       Last_parent_diam     0.016321\n",
      "39         Diam_threshold     0.020529\n",
      "40       HillmanThreshold     0.045931\n",
      "41                  Helix     0.014752\n",
      "42            Fractal_Dim     0.000000\n",
      "\n",
      "\n",
      "Decision Tree Classifier Features Importance: DataFrame\n",
      "\n",
      "\n",
      "       Height  Soma_Surface      Type  PathDistance   Taper_1\n",
      "0    0.980769      0.649038  0.701923      0.774038  0.725962\n",
      "1    0.697115      0.711538  0.754808      0.730769  0.850962\n",
      "2    0.533654      0.216346  0.348558      0.461538  0.423077\n",
      "3    0.105769      0.245192  0.456731      0.187500  0.932692\n",
      "4    0.235577      0.485577  0.500000      0.495192  0.375000\n",
      "..        ...           ...       ...           ...       ...\n",
      "204  0.658654      0.913462  0.326923      0.504808  0.673077\n",
      "205  0.947115      0.596154  0.899038      0.889423  0.923077\n",
      "206  0.278846      0.947115  0.009615      0.062500  0.014423\n",
      "207  0.480769      0.658654  0.956731      0.918269  0.894231\n",
      "208  0.817308      0.437500  0.913462      0.879808  0.870192\n",
      "\n",
      "[209 rows x 5 columns]\n",
      "     ┌─────────────────────────────────────────┐\n",
      "q_0: ┤0                                        ├\n",
      "     │                                         │\n",
      "q_1: ┤1                                        ├\n",
      "     │                                         │\n",
      "q_2: ┤2 ZZFeatureMap(x[0],x[1],x[2],x[3],x[4]) ├\n",
      "     │                                         │\n",
      "q_3: ┤3                                        ├\n",
      "     │                                         │\n",
      "q_4: ┤4                                        ├\n",
      "     └─────────────────────────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:2590: UserWarning: n_quantiles (1000) is greater than the total number of samples (209). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:2590: UserWarning: n_quantiles (1000) is greater than the total number of samples (53). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "ibmqfactory.load_account:WARNING:2022-11-24 13:28:57,604: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibmq_qasm_simulator\n",
      "ibmq_lima\n",
      "ibmq_belem\n",
      "ibmq_quito\n",
      "simulator_statevector\n",
      "simulator_mps\n",
      "simulator_extended_stabilizer\n",
      "simulator_stabilizer\n",
      "ibmq_manila\n",
      "ibm_nairobi\n",
      "ibm_oslo\n",
      "Callable kernel classification test score for q_kernel_zz: 0.4716981132075472\n",
      "\n",
      "\n",
      "Print predicted data coming from X_test as new input data\n",
      "[ 9 10  7  4 11  8  1  9 12  3 12  0  6 10  3  9 11  5  2 11 12 12  3 10\n",
      "  7  7  5 11  7  8  6  3  0  7  6  1 11  9 10  5  0  8  3 11 12  3  9  3\n",
      "  1 12  0  4  1]\n",
      "\n",
      "\n",
      "Print real values\n",
      "\n",
      "[ 9 10  7  4 11  2  4  9  5  1  6  0  8 10  7  9 11  5 10 11  2  3  5 10\n",
      "  1  3 11 11 12  5  6  7  0  1  6  7 11  0 10  5  9  8  1 11  6  3  0  5\n",
      " 12  2  9  4  1]\n",
      "\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n",
      "cross validation scores:  [0.38095238 0.5        0.57142857 0.42857143 0.58536585]\n",
      "cross validation mean:  0.4932636469221835\n",
      "Classification Report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         4\n",
      "           1       0.25      0.20      0.22         5\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.14      0.33      0.20         3\n",
      "           4       1.00      0.67      0.80         3\n",
      "           5       0.67      0.33      0.44         6\n",
      "           6       0.67      0.50      0.57         4\n",
      "           7       0.20      0.25      0.22         4\n",
      "           8       0.33      0.50      0.40         2\n",
      "           9       0.60      0.60      0.60         5\n",
      "          10       1.00      0.80      0.89         5\n",
      "          11       1.00      0.86      0.92         7\n",
      "          12       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.47        53\n",
      "   macro avg       0.49      0.43      0.44        53\n",
      "weighted avg       0.56      0.47      0.50        53\n",
      "\n",
      "                       q_kernel_zz\n",
      "Accuracy                  0.471698\n",
      "Precision                 0.471698\n",
      "Recall                    0.471698\n",
      "F1 Score                  0.471698\n",
      "Cross-validation mean     0.493264\n",
      "Cross-validation std      0.079293\n"
     ]
    }
   ],
   "source": [
    "# Loading your IBM Quantum account(s)\n",
    "from qiskit import IBMQ\n",
    "from qiskit.providers.ibmq import least_busy\n",
    "\n",
    "# Import utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Importing standard Qiskit libraries and Qiskit Machine Learning imports\n",
    "from qiskit import Aer, QuantumCircuit, BasicAer\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.visualization import circuit_drawer\n",
    "\n",
    "from typing import Union\n",
    "from qiskit_machine_learning.exceptions import QiskitMachineLearningError\n",
    "\n",
    "# seed for randomization, to keep outputs consistent\n",
    "seed = 123456\n",
    "algorithm_globals.random_seed = seed\n",
    "\n",
    "# Define parameters\n",
    "cv = 5 # Cross-validation \n",
    "feature_dimension = 5 # Features dimension\n",
    "k_features = 5 # Feature selection\n",
    "reps = 2 # Repetition\n",
    "ibm_account = 'YOUR API'\n",
    "quantum_backend = 'statevector_simulator'\n",
    "\n",
    "# Import dataset\n",
    "data = '../data/datasets/neurons_maha_soma.csv'\n",
    "neuron = pd.read_csv(data, delimiter=',')\n",
    "\n",
    "print(neuron)\n",
    "\n",
    "\n",
    "df = neuron.head(22).copy()                    # Ganglion\n",
    "df = pd.concat([df, neuron.iloc[320:340]])     # Granule\n",
    "df = pd.concat([df, neuron.iloc[1493:1513]])   # Medium Spiny\n",
    "df = pd.concat([df, neuron.iloc[1171:1191]])   # Parachromaffin\n",
    "df = pd.concat([df, neuron.iloc[10031:10051]])   # Pyramidal\n",
    "\n",
    "df = pd.concat([df, neuron.iloc[2705:2725]]) # Basket\n",
    "df = pd.concat([df, neuron.iloc[22589:22609]]) # Bitufted\n",
    "df = pd.concat([df, neuron.iloc[3175:3195]]) # Chandelier\n",
    "df = pd.concat([df, neuron.iloc[22644:22664]]) # Double bouquet\n",
    "df = pd.concat([df, neuron.iloc[3199:3219]]) # Martinotti\n",
    "df = pd.concat([df, neuron.iloc[8260:8280]]) # Nitrergic\n",
    "\n",
    "df = pd.concat([df, neuron.iloc[2255:2275]]) # Astrocytes\n",
    "df = pd.concat([df, neuron.iloc[3306:3326]]) # Microglia\n",
    "\n",
    "\n",
    "# Drop row having at least 1 missing value\n",
    "df = df.dropna()\n",
    "\n",
    "# Creating an instance of Labelencoder\n",
    "enc = LabelEncoder()\n",
    "# Assigning numerical value and storing it\n",
    "df[[\"Target\"]] = df[[\"Target\"]].apply(enc.fit_transform)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# We split our data to y (Target) and X (features)\n",
    "y = df.loc[:, df.columns == 'Target']\n",
    "# Features variables\n",
    "X = df.loc[:, df.columns != ('Target')]\n",
    "# Split data into train and test\n",
    "# Option test_size = 0.2 means that we take 20% of the data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling the data\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "Normalize = QuantileTransformer(n_quantiles=1000, output_distribution=\"uniform\")\n",
    "# Transform data\n",
    "X_train = Normalize.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns = X.columns)\n",
    "X_test = Normalize.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns = X.columns)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def embedded_decision_tree_classifier(X, y, k_features, output_folder=None):\n",
    "    '''\n",
    "    Here we use decision tree classifier to select features. We select the k best features (k_features)\n",
    "    \n",
    "    Inputs:\n",
    "        - X (features) DataFrame\n",
    "        - y (target) DataFrame\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Decision Tree Regressor Features Importance: started\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # define the model\n",
    "    model = DecisionTreeClassifier()\n",
    "    # fit the model\n",
    "    model.fit(X, y)\n",
    "    # get importance\n",
    "    importance = model.feature_importances_\n",
    "    # Get features name\n",
    "    feature_names = [f\"{i}\" for i in X.columns]\n",
    "\n",
    "    # create a data frame to visualize features importance\n",
    "    features_importance = pd.DataFrame({\"Features\": feature_names, \"Importances\":importance})\n",
    "    features_importance.set_index('Importances')\n",
    "\n",
    "    # Print features importance\n",
    "    print(\"\\n\")\n",
    "    print(\"Features Importances:\")\n",
    "    print(\"\\n\")\n",
    "    print(features_importance)\n",
    "    if output_folder is not None:\n",
    "        features_importance.to_csv(output_folder+'Decision_Tree_Classifier_Features_Importance.csv', index=False)\n",
    "\n",
    "    if output_folder is not None:\n",
    "        # plot feature importance\n",
    "        features_importance.plot(kind='bar',x='Features',y='Importances')\n",
    "        pyplot.title('Decision Tree Classifier Features Importance')\n",
    "        pyplot.tight_layout()\n",
    "        pyplot.savefig(output_folder+'Decision_Tree_Classfier_Features_Importance.png')\n",
    "    \n",
    "    # Select the k most important features\n",
    "    features_columns = []\n",
    "    # Order the features importance dataframe\n",
    "    df = pd.DataFrame(data = features_importance.sort_values(by='Importances', key=abs,ascending=False))\n",
    "    # Put the k most important features in features_columns\n",
    "    for x in range(k_features):\n",
    "        features_columns = features_columns + [df.iloc[x][0]]\n",
    "\n",
    "    # Create a new DataFrame with selected features\n",
    "    df_data = pd.DataFrame(data = X, columns = features_columns)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Decision Tree Classifier Features Importance: DataFrame\")\n",
    "    print(\"\\n\")\n",
    "    print(df_data)\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "X_train = embedded_decision_tree_classifier(X_train, y_train, k_features)\n",
    "X_test = pd.DataFrame(data = X_test, columns = X_train.columns)\n",
    "\n",
    "feature_dimension = X_train.shape[1] # Number of features\n",
    "multiclass = None\n",
    "output_folder = None\n",
    "   \n",
    "# We convert pandas DataFrame into numpy array\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "\n",
    "# seed for randomization, to keep outputs consistent\n",
    "seed = 123456\n",
    "algorithm_globals.random_seed = seed\n",
    "\n",
    "# Quantum Feature Mapping with feature_dimension = 5 and reps = 2\n",
    "qfm_zz = ZZFeatureMap(feature_dimension=feature_dimension, reps=reps, entanglement=\"linear\")\n",
    "            \n",
    "print(qfm_zz)\n",
    "    \n",
    "if 'ibmq_qasm_simulator' in quantum_backend:\n",
    "    # Use of simulator\n",
    "    # The use of these requires us to sign with an IBMQ account.\n",
    "    # Assuming the credentials are already loaded onto your computer, you sign in with\n",
    "    IBMQ.save_account(ibm_account, overwrite=True)\n",
    "    IBMQ.load_account()\n",
    "    provider = IBMQ.get_provider(hub='ibm-q')\n",
    "    # What additional backends we have available.\n",
    "    for backend in provider.backends():\n",
    "        print(backend)\n",
    "        \n",
    "    sim = provider.backends.ibmq_qasm_simulator\n",
    "    qcomp_backend = QuantumInstance(sim, shots=8192, seed_simulator=seed, seed_transpiler=seed)\n",
    "    #qcomp_backend = QuantumInstance(BasicAer.get_backend(quantum_backend), shots=1024, seed_simulator=seed, seed_transpiler=seed)\n",
    "    Q_Kernel_zz = QuantumKernel(feature_map=qfm_zz, quantum_instance=qcomp_backend)\n",
    "                \n",
    "else:\n",
    "    if 'statevector_simulator' in quantum_backend:\n",
    "        # Use of a simulator\n",
    "        # The use of these requires us to sign with an IBMQ account.\n",
    "        # Assuming the credentials are already loaded onto your computer, you sign in with\n",
    "        IBMQ.save_account(ibm_account, overwrite=True)\n",
    "        IBMQ.load_account()\n",
    "        provider = IBMQ.get_provider(hub='ibm-q')\n",
    "        # What additional backends we have available.\n",
    "        for backend in provider.backends():\n",
    "            print(backend)\n",
    "        \n",
    "        qcomp_backend = QuantumInstance(BasicAer.get_backend(quantum_backend), shots=1024, seed_simulator=seed, seed_transpiler=seed)\n",
    "        Q_Kernel_zz = QuantumKernel(feature_map=qfm_zz, quantum_instance=qcomp_backend)\n",
    "    else:\n",
    "        if 'least_busy' in quantum_backend:\n",
    "            # Use of least busy quantum hardware\n",
    "            # The use of these requires us to sign with an IBMQ account.\n",
    "            # Assuming the credentials are already loaded onto your computer, you sign in with\n",
    "            IBMQ.save_account(ibm_account, overwrite=True)\n",
    "            IBMQ.load_account()\n",
    "            provider = IBMQ.get_provider(hub='ibm-q-internal', group='deployed', project='default')\n",
    "            # What additional backends we have available.\n",
    "            for backend in provider.backends():\n",
    "                print(backend)\n",
    "                \n",
    "            device = least_busy(provider.backends(\n",
    "                        filters=lambda x: x.configuration().n_qubits >= feature_dimension   # More than 5 qubits\n",
    "                        and not x.configuration().simulator                                 # Not a simulator\n",
    "                        and x.status().operational == True                                  # Operational backend\n",
    "                    )\n",
    "                )\n",
    "            # Use of a real quantum computer\n",
    "            print(\"Available device: \", device)\n",
    "            quantum_backend = \"%s\"%device\n",
    "                \n",
    "            backend = provider.get_backend(quantum_backend)\n",
    "            real_qcomp_backend = QuantumInstance(backend, shots=1024)\n",
    "            Q_Kernel_zz = QuantumKernel(feature_map=qfm_zz, quantum_instance=real_qcomp_backend)\n",
    "\n",
    "        else:\n",
    "            # Use of a real quantum computer\n",
    "            # The use of these requires us to sign with an IBMQ account.\n",
    "            # Assuming the credentials are already loaded onto your computer, you sign in with\n",
    "            IBMQ.save_account(ibm_account, overwrite=True)\n",
    "            IBMQ.load_account()\n",
    "            provider = IBMQ.get_provider(hub='ibm-q-internal', group='deployed', project='default')\n",
    "            # What additional backends we have available.\n",
    "            for backend in provider.backends():\n",
    "                print(backend)\n",
    "                    \n",
    "            backend = provider.get_backend(quantum_backend)\n",
    "            real_qcomp_backend = QuantumInstance(backend, shots=1024)\n",
    "            Q_Kernel_zz = QuantumKernel(feature_map=qfm_zz, quantum_instance=real_qcomp_backend)\n",
    "    \n",
    "# QSVC model\n",
    "model = QSVC(quantum_kernel=Q_Kernel_zz)\n",
    "model.fit(X_train,y_train)\n",
    "score = model.score(X_test, y_test)\n",
    "print(f'Callable kernel classification test score for q_kernel_zz: {score}')\n",
    "          \n",
    "y_pred = model.predict(X_test)\n",
    "        \n",
    "print(\"\\n\")\n",
    "print(\"Print predicted data coming from X_test as new input data\")\n",
    "print(y_pred)\n",
    "print(\"\\n\")\n",
    "print(\"Print real values\\n\")\n",
    "print(y_test)\n",
    "print(\"\\n\")\n",
    "    \n",
    "# K-Fold Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "k_fold = KFold(n_splits=cv)\n",
    "score = np.zeros(cv)\n",
    "i = 0\n",
    "print(score)\n",
    "for indices_train, indices_test in k_fold.split(X_train):\n",
    "    #print(indices_train, indices_test)\n",
    "    X_train_ = X_train[indices_train]\n",
    "    X_test_ = X_train[indices_test]\n",
    "    y_train_ = y_train[indices_train]\n",
    "    y_test_ = y_train[indices_test]\n",
    " \n",
    "    # fit classifier to data\n",
    "    model.fit(X_train_, y_train_)\n",
    "\n",
    "    # score classifier\n",
    "    score[i] = model.score(X_test_, y_test_)\n",
    "    i = i + 1\n",
    "\n",
    "import math\n",
    "print(\"cross validation scores: \", score)\n",
    "cross_mean = sum(score) / len(score)\n",
    "cross_var = sum(pow(x - cross_mean,2) for x in score) / len(score)  # variance\n",
    "cross_std  = math.sqrt(cross_var)  # standard deviation\n",
    "print(\"cross validation mean: \", cross_mean)\n",
    "    \n",
    "results = [metrics.accuracy_score(y_test, y_pred),metrics.precision_score(y_test, y_pred, average='micro'),metrics.recall_score(y_test, y_pred, average='micro'),metrics.f1_score(y_test, y_pred, average='micro'), cross_mean, cross_std]\n",
    "    \n",
    "metrics_dataframe = pd.DataFrame(results, index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Cross-validation mean\", \"Cross-validation std\"], columns=['q_kernel_zz'])\n",
    "\n",
    "print('Classification Report: \\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "        \n",
    "print(metrics_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df42a739",
   "metadata": {},
   "source": [
    "# Pegasos Quantum Support Vector Classifier: Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358873e",
   "metadata": {},
   "source": [
    "There is also an alternative method to QSVC (which use the dual optimization from scikit-learn) using the Pegasos algorithm from Shalev-Shwartz where another SVM based algorithm benefits from the quantum kernel method. PegasosQSVC yields a training complexity that is independent of the size of the training set. This means that it could train faster than QSVC with large training sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d229bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "configrc.store_credentials:WARNING:2022-06-05 11:39:04,764: Credentials already present. Set overwrite=True to overwrite.\n",
      "ibmqfactory.load_account:WARNING:2022-06-05 11:39:05,848: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibmq_qasm_simulator\n",
      "ibmq_armonk\n",
      "ibmq_santiago\n",
      "ibmq_bogota\n",
      "ibmq_lima\n",
      "ibmq_belem\n",
      "ibmq_quito\n",
      "simulator_statevector\n",
      "simulator_mps\n",
      "simulator_extended_stabilizer\n",
      "simulator_stabilizer\n",
      "ibmq_manila\n",
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n",
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n",
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n",
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n",
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n",
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n",
      "     ┌─────────────────────────────┐\n",
      "q_0: ┤0                            ├\n",
      "     │  PauliFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                            ├\n",
      "     └─────────────────────────────┘\n",
      "        PCA_1      PCA_2\n",
      "0    1.435834   4.081395\n",
      "1    5.773557  10.022009\n",
      "2   21.318734  -4.598521\n",
      "3   -3.151619  -1.563259\n",
      "4    0.668559   0.301271\n",
      "5   -1.165522   0.369769\n",
      "6   -0.958028  -1.190758\n",
      "7   -3.716388  -1.479628\n",
      "8   -3.968132  -1.303697\n",
      "9    5.667760  -3.158447\n",
      "10  -0.787751  -0.148257\n",
      "11  -3.506257  -1.179403\n",
      "12  -1.617898   0.087098\n",
      "13  -2.480529  -0.935191\n",
      "14  -4.335223  -1.390716\n",
      "15  -1.048610  -0.730497\n",
      "16   3.124327   3.135691\n",
      "17   3.198947  -1.246605\n",
      "18  -1.282505   2.405743\n",
      "19  -4.256384  -1.492572\n",
      "20  -1.835022   0.466993\n",
      "21  -2.673096  -1.118469\n",
      "22  -3.645921  -1.479659\n",
      "23  -3.763482  -1.566059\n",
      "24  -3.636642  -1.489347\n",
      "25  -1.667317  -1.234876\n",
      "26  -0.849866   5.925350\n",
      "27   1.505479  -2.277992\n",
      "28  -3.051316  -0.371275\n",
      "29   6.733528   1.484747\n",
      "30  -1.095088   3.026743\n",
      "31   5.065872  -1.351583\n",
      "      PCA_1     PCA_2\n",
      "0 -3.569388 -0.568268\n",
      "1  1.036985  6.469456\n",
      "2 -3.763126 -0.032492\n",
      "3  8.208539 -5.295320\n",
      "4  1.561053 -1.076364\n",
      "5 -4.648621 -3.235642\n",
      "6  5.187216  3.940087\n",
      "7 -4.012659 -0.201456\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only binary classification is supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/4vnghq3579l_6xbflfl1hk180000gn/T/ipykernel_64364/4055774365.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;31m# iterate over classifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Callable kernel classification test score for {name}: {score}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_machine_learning/algorithms/classifiers/pegasos_qsvc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has to be a 1D array\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only binary classification is supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'X' and 'y' have to contain the same number of samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only binary classification is supported"
     ]
    }
   ],
   "source": [
    "# Loading your IBM Quantum account(s)\n",
    "from qiskit import IBMQ\n",
    "IBMQ.save_account('YOUR API')\n",
    "\n",
    "# Import utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Importing standard Qiskit libraries and Qiskit Machine Learning imports\n",
    "from qiskit import BasicAer\n",
    "from qiskit.circuit.library import ZZFeatureMap, PauliFeatureMap\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.algorithms import PegasosQSVC\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "from qiskit.algorithms.optimizers import COBYLA\n",
    "\n",
    "# Backend objects can also be set up using the IBMQ package.\n",
    "# The use of these requires us to sign with an IBMQ account.\n",
    "# Assuming the credentials are already loaded onto your computer, you sign in with\n",
    "IBMQ.load_account()\n",
    "provider = IBMQ.get_provider(hub='ibm-q')\n",
    "backend = provider.get_backend('ibmq_lima')\n",
    "\n",
    "# What additional backends we have available.\n",
    "for backend in provider.backends():\n",
    "    print(backend)\n",
    "    \n",
    "# seed for randomization, to keep outputs consistent\n",
    "seed = 123456\n",
    "algorithm_globals.random_seed = seed\n",
    "\n",
    "# number of qubits is equal to the number of features\n",
    "num_qubits = 2\n",
    "\n",
    "# number of steps performed during the training procedure\n",
    "tau = 100\n",
    "\n",
    "# regularization parameter\n",
    "C = 1000\n",
    "\n",
    "# Encoding Functions\n",
    "\n",
    "def data_map_8(x: np.ndarray) -> float:\n",
    "    coeff = x[0] if len(x) == 1 else reduce(lambda m, n: np.pi*(m * n), x)\n",
    "    return coeff\n",
    "\n",
    "def data_map_9(x: np.ndarray) -> float:\n",
    "    coeff = x[0] if len(x) == 1 else reduce(lambda m, n: (np.pi/2)*(m * n), 1 - x)\n",
    "    return coeff\n",
    "\n",
    "def data_map_10(x: np.ndarray) -> float:\n",
    "    coeff = x[0] if len(x) == 1 else reduce(lambda m, n: np.pi*np.exp(((n - m)*(n - m))/8), x)\n",
    "    return coeff\n",
    "\n",
    "def data_map_11(x: np.ndarray) -> float:\n",
    "    coeff = x[0] if len(x) == 1 else reduce(lambda m, n: (np.pi/3)*(m * n), 1/(np.cos(x)))\n",
    "    return coeff\n",
    "\n",
    "def data_map_12(x: np.ndarray) -> float:\n",
    "    coeff = x[0] if len(x) == 1 else reduce(lambda m, n: np.pi*(m * n), np.cos(x))\n",
    "    return coeff\n",
    "    \n",
    "# Quantum Feature Mapping with feature_dimension = 2 and reps = 2\n",
    "\n",
    "qfm_default = PauliFeatureMap(feature_dimension=2,\n",
    "                                    paulis = ['ZI','IZ','ZZ'],\n",
    "                                 reps=2, entanglement='full')\n",
    "print(qfm_default)\n",
    "qfm_8 = PauliFeatureMap(feature_dimension=2,\n",
    "                                    paulis = ['ZI','IZ','ZZ'],\n",
    "                                 reps=2, entanglement='full', data_map_func=data_map_8)\n",
    "print(qfm_8)\n",
    "qfm_9 = PauliFeatureMap(feature_dimension=2,\n",
    "                                    paulis = ['ZI','IZ','ZZ'],\n",
    "                                 reps=2, entanglement='full', data_map_func=data_map_9)\n",
    "print(qfm_9)\n",
    "qfm_10 = PauliFeatureMap(feature_dimension=2,\n",
    "                                    paulis = ['ZI','IZ','ZZ'],\n",
    "                                 reps=2, entanglement='full', data_map_func=data_map_10)\n",
    "print(qfm_10)\n",
    "qfm_11 = PauliFeatureMap(feature_dimension=2,\n",
    "                                    paulis = ['ZI','IZ','ZZ'],\n",
    "                                 reps=2, entanglement='full', data_map_func=data_map_11)\n",
    "print(qfm_11)\n",
    "qfm_12 = PauliFeatureMap(feature_dimension=2,\n",
    "                                    paulis = ['ZI','IZ','ZZ'],\n",
    "                                 reps=2, entanglement='full', data_map_func=data_map_12)\n",
    "print(qfm_12)\n",
    "                                 \n",
    "print(qfm_8.draw())\n",
    "\n",
    "# Use of a simulator (qasm_simulator)\n",
    "\n",
    "qcomp_backend = QuantumInstance(BasicAer.get_backend('qasm_simulator'), shots=1024,\n",
    "                                seed_simulator=seed, seed_transpiler=seed)\n",
    "Q_Kernel_default = QuantumKernel(feature_map=qfm_default, quantum_instance=qcomp_backend)\n",
    "Q_Kernel_8 = QuantumKernel(feature_map=qfm_8, quantum_instance=qcomp_backend)\n",
    "Q_Kernel_9 = QuantumKernel(feature_map=qfm_9, quantum_instance=qcomp_backend)\n",
    "Q_Kernel_10 = QuantumKernel(feature_map=qfm_10, quantum_instance=qcomp_backend)\n",
    "Q_Kernel_11 = QuantumKernel(feature_map=qfm_11, quantum_instance=qcomp_backend)\n",
    "Q_Kernel_12 = QuantumKernel(feature_map=qfm_12, quantum_instance=qcomp_backend)\n",
    "\n",
    "names = [\"Q_Kernel_default\", \"Q_Kernel_8\", \"Q_Kernel_9\",\n",
    "         \"Q_Kernel_10\", \"Q_Kernel_11\", \"Q_Kernel_12\"]\n",
    "\n",
    "classifiers = [\n",
    "    PegasosQSVC(quantum_kernel=Q_Kernel_default, C=C, num_steps=tau),\n",
    "    PegasosQSVC(quantum_kernel=Q_Kernel_8, C=C, num_steps=tau),\n",
    "    PegasosQSVC(quantum_kernel=Q_Kernel_9, C=C, num_steps=tau),\n",
    "    PegasosQSVC(quantum_kernel=Q_Kernel_10, C=C, num_steps=tau),\n",
    "    PegasosQSVC(quantum_kernel=Q_Kernel_11, C=C, num_steps=tau),\n",
    "    PegasosQSVC(quantum_kernel=Q_Kernel_12, C=C, num_steps=tau),\n",
    "              ]\n",
    "\n",
    "# Import dataset\n",
    "data = '../data/datasets/neurons_test.csv'\n",
    "df = pd.read_csv(data, delimiter=';')\n",
    "\n",
    "# Drop row having at least 1 missing value\n",
    "df = df.dropna()\n",
    "\n",
    "# Creating an instance of Labelencoder\n",
    "enc = LabelEncoder()\n",
    "# Assigning numerical value and storing it\n",
    "df[[\"Target\"]] = df[[\"Target\"]].apply(enc.fit_transform)\n",
    "\n",
    "# Divide the data, y the variable to predict (Target) and X the features\n",
    "X = df[df.columns[1:]]\n",
    "y = df['Target']\n",
    "\n",
    "# Splitting the data : training and test (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Scaling the data\n",
    "Normalize = preprocessing.StandardScaler()\n",
    "# Transform data\n",
    "X_train = Normalize.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns = X.columns)\n",
    "X_test = Normalize.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns = X.columns)\n",
    "\n",
    "# Dimension Reduction with PCA (with two principal compoenents)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "# transform data\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.fit_transform(X_test)\n",
    "# Define a new DataFrame with two column (the principal components)\n",
    "component_columns = []\n",
    "for x in (n+1 for n in range(2)):\n",
    "    component_columns = component_columns + ['PCA_%i'%x]\n",
    "X_train = pd.DataFrame(data = X_train, columns = component_columns)\n",
    "X_test = pd.DataFrame(data = X_test, columns = component_columns)\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print(f'Callable kernel classification test score for {name}: {score}')\n",
    "        \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Provide metrics over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "        print(\"\\n\")\n",
    "        print(name)\n",
    "        print(\"\\n\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "    \n",
    "        print(\"\\n\")\n",
    "        print(\"Print predicted data coming from X_test as new input data\")\n",
    "        print(y_pred)\n",
    "        print(\"\\n\")\n",
    "        print(\"Print real values\\n\")\n",
    "        print(y_test)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "        print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "        print(\"Precision:\", metrics.precision_score(y_test, y_pred, average='micro'))\n",
    "        print(\"Recall:\", metrics.recall_score(y_test, y_pred, average='micro'))\n",
    "        print(\"f1 Score:\", metrics.f1_score(y_test, y_pred, average='micro'))\n",
    "        print(\"Cross Validation Mean:\", cross_val_score(clf, X_train, y_train, cv=5).mean())\n",
    "        print(\"Cross Validation Std:\", cross_val_score(clf, X_train, y_train, cv=5).std())\n",
    "        \n",
    "        \n",
    "        results = [metrics.accuracy_score(y_test, y_pred),metrics.precision_score(y_test, y_pred, average='micro'),metrics.recall_score(y_test, y_pred, average='micro'),metrics.f1_score(y_test, y_pred, average='micro'), cross_val_score(clf, X_train, y_train, cv=5).mean(), cross_val_score(clf, X_train, y_train, cv=5).std()]\n",
    "        metrics_dataframe = pd.DataFrame(results, index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Cross-validation mean\", \"Cross-validation std\"], columns=[name])\n",
    "\n",
    "        print('Classification Report: \\n')\n",
    "        print(classification_report(y_test,y_pred))\n",
    "    \n",
    "        print('Metrics:')\n",
    "        print(metrics_dataframe)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f90e11",
   "metadata": {},
   "source": [
    "## Quantum Kernel Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43565c66",
   "metadata": {},
   "source": [
    "It is also possible to train a quantum kernel with Quantum Kernel Alignment (QKA) that iteratively adapts a parametrized quantum kernel to a dataset and converging to the maximum SVM margin at the same time. To implement it, we prepare the dataset as usual and define the quantum feature map. Then, we will use QuantumKernelTrained.fit method to train the kernel parameters and pass it to a machine learning model.\n",
    "Source: https://lab.quantum-computing.ibm.com/user/5ae8692a0f0205003930696d/lab/workspaces/auto-s/tree/qiskit-tutorials/qiskit-machine-learning/08_quantum_kernel_trainer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85b231d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "configrc.store_credentials:WARNING:2022-07-08 18:52:43,605: Credentials already present. Set overwrite=True to overwrite.\n",
      "ibmqfactory.load_account:WARNING:2022-07-08 18:52:45,795: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ┌──────────┐┌──────────────────────────┐\n",
      "q_0: ┤ Ry(θ[0]) ├┤0                         ├\n",
      "     ├──────────┤│  ZZFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤ Ry(θ[0]) ├┤1                         ├\n",
      "     └──────────┘└──────────────────────────┘\n",
      "Trainable parameters: θ, ['θ[0]']\n",
      "     ┌──────────────────────────┐\n",
      "q_0: ┤0                         ├\n",
      "     │  ZZFeatureMap(x[0],x[1]) │\n",
      "q_1: ┤1                         ├\n",
      "     └──────────────────────────┘\n",
      "{   'optimal_parameters': {ParameterVectorElement(θ[0]): 1.3059540613374132},\n",
      "    'optimal_point': array([1.30595406]),\n",
      "    'optimal_value': 18.27409165606242,\n",
      "    'optimizer_evals': 30,\n",
      "    'optimizer_time': None,\n",
      "    'quantum_kernel': <qiskit_machine_learning.kernels.quantum_kernel.QuantumKernel object at 0x12e514f40>}\n",
      "accuracy test: 0.5595238095238095\n",
      "\n",
      "\n",
      "Print predicted data coming from X_test as new input data\n",
      "[2 2 2 1 0 0 1 1 0 1 1 2]\n",
      "\n",
      "\n",
      "Print real values\n",
      "\n",
      "377      2\n",
      "17034    0\n",
      "381      2\n",
      "17051    0\n",
      "17052    0\n",
      "374      2\n",
      "9        1\n",
      "17041    0\n",
      "388      2\n",
      "378      2\n",
      "382      2\n",
      "384      2\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.25      0.29         4\n",
      "           1       0.20      1.00      0.33         1\n",
      "           2       0.75      0.43      0.55         7\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.43      0.56      0.39        12\n",
      "weighted avg       0.57      0.42      0.44        12\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_kernel_zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross-validation mean</th>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross-validation std</th>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       q_kernel_zz\n",
       "Accuracy                  0.416667\n",
       "Precision                 0.416667\n",
       "Recall                    0.416667\n",
       "F1 Score                  0.416667\n",
       "Cross-validation mean     0.416667\n",
       "Cross-validation std      0.041667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading your IBM Quantum account(s)\n",
    "from qiskit import IBMQ\n",
    "\n",
    "# Import utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Importing standard Qiskit libraries and Qiskit Machine Learning imports\n",
    "from qiskit import BasicAer\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.providers.aer import AerSimulator\n",
    "from qiskit.visualization import circuit_drawer\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.kernels.algorithms import QuantumKernelTrainer\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "\n",
    "# Import dataset\n",
    "data = '../data/datasets/neurons.csv'\n",
    "neuron = pd.read_csv(data, delimiter=';')\n",
    "\n",
    "# Select a subset of the data composed of three classes\n",
    "df = neuron.head(20).copy()                    # Ganglion\n",
    "df = pd.concat([df, neuron.iloc[373:393]])     # Granule\n",
    "df = pd.concat([df, neuron.iloc[17033:17053]]) # Basket\n",
    "\n",
    "# seed for randomization, to keep outputs consistent\n",
    "seed = 123456\n",
    "algorithm_globals.random_seed = seed\n",
    "\n",
    "# Drop row having at least 1 missing value\n",
    "df = df.dropna()\n",
    "\n",
    "# Creating an instance of Labelencoder\n",
    "enc = LabelEncoder()\n",
    "# Assigning numerical value and storing it\n",
    "df[[\"Target\"]] = df[[\"Target\"]].apply(enc.fit_transform)\n",
    "\n",
    "# Divide the data, y the variable to predict (Target) and X the features\n",
    "X = df[df.columns[1:]]\n",
    "y = df['Target']\n",
    "\n",
    "# Splitting the data : training and test (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Scaling the data\n",
    "Normalize = preprocessing.StandardScaler()\n",
    "# Transform data\n",
    "X_train = Normalize.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns = X.columns)\n",
    "X_test = Normalize.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns = X.columns)\n",
    "\n",
    "# Dimension Reduction with PCA (with two principal compoenents)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "# transform data\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.fit_transform(X_test)\n",
    "# Define a new DataFrame with two column (the principal components)\n",
    "component_columns = []\n",
    "for x in (n+1 for n in range(2)):\n",
    "    component_columns = component_columns + ['PCA_%i'%x]\n",
    "X_train = pd.DataFrame(data = X_train, columns = component_columns)\n",
    "X_test = pd.DataFrame(data = X_test, columns = component_columns)\n",
    "\n",
    "# Define some parameters\n",
    "feature_dimension = 2 # number of features\n",
    "reps = 2 # number of repetitions\n",
    "quantum_backend = 'qasm_simulator' # quantum backend\n",
    "cv = 2 # Cross-validation\n",
    "circuits = 2 # number of circuits\n",
    "\n",
    "# The use of these requires us to sign with an IBMQ account.\n",
    "# Assuming the credentials are already loaded onto your computer, you sign in with\n",
    "IBMQ.save_account('YOUR API')\n",
    "IBMQ.load_account()\n",
    "provider = IBMQ.get_provider(hub='ibm-q')\n",
    "\n",
    "# Define a callback class for our optimizer\n",
    "class QKTCallback:\n",
    "    \"\"\"Callback wrapper class.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._data = [[] for i in range(5)]\n",
    "\n",
    "    def callback(self, x0, x1=None, x2=None, x3=None, x4=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x0: number of function evaluations\n",
    "            x1: the parameters\n",
    "            x2: the function value\n",
    "            x3: the stepsize\n",
    "            x4: whether the step was accepted\n",
    "        \"\"\"\n",
    "        self._data[0].append(x0)\n",
    "        self._data[1].append(x1)\n",
    "        self._data[2].append(x2)\n",
    "        self._data[3].append(x3)\n",
    "        self._data[4].append(x4)\n",
    "\n",
    "    def get_callback_data(self):\n",
    "        return self._data\n",
    "\n",
    "    def clear_callback_data(self):\n",
    "        self._data = [[] for i in range(5)]\n",
    "    \n",
    "# seed for randomization, to keep outputs consistent\n",
    "seed = 123456\n",
    "algorithm_globals.random_seed = seed\n",
    "\n",
    "# Rotational layer to train. We rotate each qubit the same amount.\n",
    "from qiskit.circuit import ParameterVector\n",
    "user_params = ParameterVector(\"θ\", 1)\n",
    "fm0 = QuantumCircuit(circuits) # Number of circuits\n",
    "fm0.ry(user_params[0], 0)\n",
    "fm0.ry(user_params[0], 1)\n",
    "\n",
    "# Use ZZFeatureMap \n",
    "qfm_zz = ZZFeatureMap(feature_dimension)\n",
    "\n",
    "# Create the feature map\n",
    "fm = fm0.compose(qfm_zz)\n",
    "\n",
    "print(circuit_drawer(fm))\n",
    "print(f\"Trainable parameters: {user_params}\")\n",
    "\n",
    "print(qfm_zz)\n",
    "\n",
    "if 'qasm_simulator' in quantum_backend:\n",
    "    # Use of a simulator\n",
    "    qcomp_backend = QuantumInstance(BasicAer.get_backend(quantum_backend), shots=1024, seed_simulator=seed, seed_transpiler=seed)\n",
    "    Q_Kernel_zz = QuantumKernel(feature_map=fm, user_parameters=user_params, quantum_instance=qcomp_backend)\n",
    "else:\n",
    "    # Use of a real quantum computer\n",
    "    real_qcomp_backend = QuantumInstance(provider.get_backend(quantum_backend), shots=1024)\n",
    "    Q_Kernel_zz = QuantumKernel(feature_map=fm, user_parameters=user_params, quantum_instance=real_qcomp_backend)\n",
    "\n",
    "\n",
    "# Instantiate quantum kernel\n",
    "quant_kernel = QuantumKernel(fm, user_parameters=user_params, quantum_instance=qcomp_backend)\n",
    "\n",
    "# Set up the optimizer\n",
    "cb_qkt = QKTCallback()\n",
    "spsa_opt = SPSA(maxiter=10, callback=cb_qkt.callback, learning_rate=0.05, perturbation=0.05)\n",
    "\n",
    "# Instantiate a quantum kernel trainer\n",
    "qkt = QuantumKernelTrainer(\n",
    "    quantum_kernel=quant_kernel, loss=\"svc_loss\", optimizer=spsa_opt, initial_point=[np.pi / 2]\n",
    ")\n",
    "\n",
    "# Train the kernel using QKT directly\n",
    "qka_results = qkt.fit(X_train, y_train)\n",
    "optimized_kernel = qka_results.quantum_kernel\n",
    "print(qka_results)\n",
    "\n",
    "# Use QSVC for classification\n",
    "qsvc = QSVC(quantum_kernel=optimized_kernel)\n",
    "\n",
    "# Fit the QSVC\n",
    "qsvc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "y_pred = qsvc.predict(X_test)\n",
    "\n",
    "# Evalaute the test accuracy\n",
    "accuracy_test = metrics.balanced_accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(f\"accuracy test: {accuracy_test}\")\n",
    "\n",
    "# Print predicted values and real values of the X_test dataset\n",
    "print(\"\\n\")\n",
    "print(\"Print predicted data coming from X_test as new input data\")\n",
    "print(y_pred)\n",
    "print(\"\\n\")\n",
    "print(\"Print real values\\n\")\n",
    "print(y_test)\n",
    "print(\"\\n\")\n",
    "    \n",
    "# Print accuracy metrics of the model\n",
    "results = [metrics.accuracy_score(y_test, y_pred),metrics.precision_score(y_test, y_pred, average='micro'),metrics.recall_score(y_test, y_pred, average='micro'),metrics.f1_score(y_test, y_pred, average='micro'), cross_val_score(qsvc, X_train, y_train, cv=cv).mean(), cross_val_score(qsvc, X_train, y_train, cv=cv).std()]\n",
    "metrics_dataframe = pd.DataFrame(results, index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Cross-validation mean\", \"Cross-validation std\"], columns=['q_kernel_training'])\n",
    "print('Classification Report: \\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "        \n",
    "metrics_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1df630",
   "metadata": {},
   "source": [
    "# Quantum Kernel Alignment with Qiskit Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d63731",
   "metadata": {},
   "source": [
    "Source: https://qiskit.org/documentation/partners/qiskit_ibm_runtime/tutorials/qka.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40d4b7e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SymbolicPulse' from 'qiskit.pulse.library' (/usr/local/lib/python3.9/site-packages/qiskit/pulse/library/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/4vnghq3579l_6xbflfl1hk180000gn/T/ipykernel_69411/4011139114.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"..\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add program_source directory to the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_ibm_runtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQiskitRuntimeService\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQiskitRuntimeService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ibm_quantum\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mqiskit_runtime_service\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQiskitRuntimeService\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mibm_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIBMBackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mruntime_job\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRuntimeJob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/qiskit_runtime_service.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproviderutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilter_backends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_ibm_runtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mibm_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maccounts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccountManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAccount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAccountType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChannelType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mproxies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProxyConfiguration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/ibm_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccountClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseBackendClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIBMBackendApiProtocolError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/api/clients/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\"\"\"IBM Quantum API clients.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWebsocketClientCloseCode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maccount\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccountClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAuthClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/api/clients/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwebsocket\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWebSocketApp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTATUS_NORMAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTATUS_ABNORMAL_CLOSED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_parameters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClientParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWebsocketError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWebsocketTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/api/client_parameters.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_runtime_api_base_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantumAuth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCloudAuth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProxyConfiguration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_python_identifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_crn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_runtime_api_base_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolve_crn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRuntimeEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeDecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_base64_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/utils/json.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_terra_version_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m from ..qpy import (\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0m_write_parameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0m_write_parameter_expression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/qpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \"\"\"\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# For backward compatibility. Provide, Runtime, Experiment call these private functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/qpy/interface.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecate_arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQpyError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/qpy/binary_io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\"\"\"Read and write QPY-serializable objects.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m from .value import (\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdumps_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mloads_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/qpy/binary_io/value.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptionals\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_optional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/qiskit_ibm_runtime/qpy/type_keys.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mRelativeBarrier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m )\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpulse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWaveform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymbolicPulse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpulse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mScheduleBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m from qiskit.pulse.transforms.alignments import (\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SymbolicPulse' from 'qiskit.pulse.library' (/usr/local/lib/python3.9/site-packages/qiskit/pulse/library/__init__.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")  # Add program_source directory to the path\n",
    "\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "\n",
    "service = QiskitRuntimeService(channel=\"ibm_quantum\")\n",
    "backend = service.backend(\"ibmq_montreal\")\n",
    "\n",
    "# Loading your IBM Quantum account(s)\n",
    "from qiskit import IBMQ\n",
    "IBMQ.save_account('YOUR API')\n",
    "IBMQ.load_account()\n",
    "provider = IBMQ.get_provider(hub='ibm-q')\n",
    "\n",
    "# Import utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import dataset\n",
    "data = '../data/datasets/neurons.csv'\n",
    "neuron = pd.read_csv(data, delimiter=';')\n",
    "\n",
    "df = neuron.head(371).copy()                     # Ganglion\n",
    "df = pd.concat([df, neuron.iloc[373:1410]])    # Granule\n",
    "df = pd.concat([df, neuron.iloc[1411:2272]])   # Medium Spiny\n",
    "#df = pd.concat([df, neuron.iloc[2273:2797]])   # Parachromaffin\n",
    "#df = pd.concat([df, neuron.iloc[2840:3294]])   # Purkinje\n",
    "#df = pd.concat([df, neuron.iloc[3295:17032]])  # Pyramidal\n",
    "\n",
    "#df = pd.concat([df, neuron.iloc[17033:17505]]) # Basket\n",
    "#df = pd.concat([df, neuron.iloc[17506:17572]]) # Bitufted\n",
    "#df = pd.concat([df, neuron.iloc[17573:17598]]) # Chandelier\n",
    "#df = pd.concat([df, neuron.iloc[17599:17648]]) # Double bouquet\n",
    "#df = pd.concat([df, neuron.iloc[17649:17785]]) # Martinotti\n",
    "#df = pd.concat([df, neuron.iloc[17786:19829]]) # Nitrergic\n",
    "\n",
    "#df = pd.concat([df, neuron.iloc[19830:21436]]) # Astrocytes\n",
    "#df = pd.concat([df, neuron.iloc[21437:27882]]) # Microglia\n",
    "\n",
    "# Drop row having at least 1 missing value\n",
    "df = df.dropna()\n",
    "\n",
    "# Creating an instance of Labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "# Assigning numerical value and storing it\n",
    "df[[\"Target\"]] = df[[\"Target\"]].apply(enc.fit_transform)\n",
    "\n",
    "# Divide the data, y the variable to predict (Target) and X the features\n",
    "X = df[df.columns[1:]]\n",
    "y = df['Target']\n",
    "\n",
    "# Splitting the data : training and test (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Scaling the data\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "Normalize = QuantileTransformer(n_quantiles=1000, output_distribution=\"uniform\")\n",
    "# Transform data\n",
    "X_train = Normalize.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns = X.columns)\n",
    "X_test = Normalize.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns = X.columns)\n",
    "\n",
    "\n",
    "# Embedded decision tree classifier\n",
    "\n",
    "def embedded_decision_tree_classifier(X, y, k_features, output_folder=None):\n",
    "    '''\n",
    "    Here we use decision tree classifier to select features. We select the k best features (k_features)\n",
    "    \n",
    "    Inputs:\n",
    "        - X (features) DataFrame\n",
    "        - y (target) DataFrame\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Decision Tree Regressor Features Importance: started\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # define the model\n",
    "    model = DecisionTreeClassifier()\n",
    "    # fit the model\n",
    "    model.fit(X, y)\n",
    "    # get importance\n",
    "    importance = model.feature_importances_\n",
    "    # Get features name\n",
    "    feature_names = [f\"{i}\" for i in X.columns]\n",
    "\n",
    "    # create a data frame to visualize features importance\n",
    "    features_importance = pd.DataFrame({\"Features\": feature_names, \"Importances\":importance})\n",
    "    features_importance.set_index('Importances')\n",
    "\n",
    "    # Print features importance\n",
    "    print(\"\\n\")\n",
    "    print(\"Features Importances:\")\n",
    "    print(\"\\n\")\n",
    "    print(features_importance)\n",
    "    if output_folder is not None:\n",
    "        features_importance.to_csv(output_folder+'Decision_Tree_Classifier_Features_Importance.csv', index=False)\n",
    "\n",
    "    if output_folder is not None:\n",
    "        # plot feature importance\n",
    "        features_importance.plot(kind='bar',x='Features',y='Importances')\n",
    "        pyplot.title('Decision Tree Classifier Features Importance')\n",
    "        pyplot.tight_layout()\n",
    "        pyplot.savefig(output_folder+'Decision_Tree_Classfier_Features_Importance.png')\n",
    "    \n",
    "    # Select the k most important features\n",
    "    features_columns = []\n",
    "    # Order the features importance dataframe\n",
    "    df = pd.DataFrame(data = features_importance.sort_values(by='Importances', key=abs,ascending=False))\n",
    "    # Put the k most important features in features_columns\n",
    "    for x in range(k_features):\n",
    "        features_columns = features_columns + [df.iloc[x][0]]\n",
    "\n",
    "    # Create a new DataFrame with selected features\n",
    "    df_data = pd.DataFrame(data = X, columns = features_columns)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Decision Tree Classifier Features Importance: DataFrame\")\n",
    "    print(\"\\n\")\n",
    "    print(df_data)\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "# Feature selection (we we take the top 10 features)\n",
    "k_features = 10\n",
    "X_train = embedded_decision_tree_classifier(X_train, y_train, k_features)\n",
    "X_test = pd.DataFrame(data = X_test, columns = X_train.columns)\n",
    "\n",
    "from program_source.qka import FeatureMap\n",
    "\n",
    "d = 10  # feature dimension is twice the qubit number (To check)\n",
    "\n",
    "em = [[0,1],[2,3],[4,5],[6,7],[8,9],[1,2],[3,4],[5,6],[7,8]]  # we'll match this to the 10-qubit graph\n",
    "\n",
    "fm = FeatureMap(feature_dimension=d, entangler_map=em)  # define the feature map\n",
    "initial_point = [0.1]  # set the initial parameter for the feature map\n",
    "\n",
    "\n",
    "from qiskit.tools.visualization import circuit_drawer\n",
    "\n",
    "circuit_drawer(\n",
    "    fm.construct_circuit(x=X_train[0], parameters=initial_point),\n",
    "    output=\"text\",\n",
    "    fold=200,\n",
    ")\n",
    "\n",
    "C = 1  # SVM soft-margin penalty\n",
    "maxiters = 10  # number of SPSA iterations\n",
    "\n",
    "initial_layout = [9, 8, 11, 14, 16, 19, 22, 25, 24, 23]       # see figure above for the 10-qubit graph\n",
    "\n",
    "print(service.program(\"quantum-kernel-alignment\"))\n",
    "\n",
    "def interim_result_callback(job_id, interim_result):\n",
    "    print(f\"interim result: {interim_result}\\n\")\n",
    "\n",
    "    program_inputs = {\n",
    "    \"feature_map\": fm,\n",
    "    \"data\": X_train,\n",
    "    \"labels\": y_train,\n",
    "    \"initial_kernel_parameters\": initial_point,\n",
    "    \"maxiters\": maxiters,\n",
    "    \"C\": C,\n",
    "    \"initial_layout\": initial_layout,\n",
    "}\n",
    "\n",
    "options = {\"backend_name\": backend.name}\n",
    "\n",
    "job = service.run(\n",
    "    program_id=\"quantum-kernel-alignment\",\n",
    "    options=options,\n",
    "    inputs=program_inputs,\n",
    "    callback=interim_result_callback,\n",
    ")\n",
    "\n",
    "print(job.job_id)\n",
    "result = job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"aligned_kernel_parameters: {result['aligned_kernel_parameters']}\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import cm\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.imshow(\n",
    "    result[\"aligned_kernel_matrix\"] - np.identity(2 * num_train),\n",
    "    cmap=cm.get_cmap(\"bwr\", 20),\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
